{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Modeling and Evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Dataset\n",
    "- inputs/mildew_dataset/cherry-leaves/train\n",
    "- inputs/mildew_dataset/cherry-leaves/validation\n",
    "- inputs/mildew_dataset/cherry-leaves/test\n",
    "\n",
    "Precomputed Features (from Data Visualization Notebook)\n",
    "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
    "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
    "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "### Data Processing & Visualization\n",
    "- **Dataset Distribution Plot** → Confirms balanced data split across training, validation, and test sets.  \n",
    "- **Data Augmentation Visualization** → Showcases applied transformations (rotation, flipping, zooming).  \n",
    "\n",
    "### Model Training & Evaluation\n",
    "- **Baseline CNN Models (Sigmoid & Softmax)** → Initial experiments to establish a benchmark.  \n",
    "- **MobileNetV2 Fine-Tuning** → Explored optimized architectures with different hyperparameters.  \n",
    "- **Best Model Selection** → Chose the most balanced model based on test accuracy, generalization, and robustness.  \n",
    "- **Saved Trained Model** → Final MobileNetV2 model stored for deployment.  \n",
    "\n",
    "### Model Performance & Explainability\n",
    "- **Learning Curves** → Visualizes loss and accuracy trends over epochs.  \n",
    "- **Histograms** → Displays predicted probability distributions.  \n",
    "- **Overfitting & Generalization Check** → Assesses potential overfitting using accuracy and loss gaps.  \n",
    "- **Confusion Matrices** → Shows classification performance for train, validation, and test sets.  \n",
    "- **Classification Reports** → Provides precision, recall, and F1-score analysis.  \n",
    "- **ROC Curves** → Evaluates model performance using Receiver Operating Characteristic analysis.  \n",
    "- **Business Goal Validation** → Confirms if the model meets the required accuracy threshold.  \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "- **Business Impact:** Enables early detection of powdery mildew, reducing manual inspection and improving monitoring.  \n",
    "- **Data-Driven Improvements:** Model refinements were based on data insights, ensuring balanced class distribution.  \n",
    "- **Deployment:** The optimized model is ready for Streamlit integration for real-world use.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/workspaces/mildew-detector\")\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "#### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "## Set Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directories\n",
    "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
    "train_path = os.path.join(my_data_dir, 'train')\n",
    "val_path = os.path.join(my_data_dir, 'validation')\n",
    "test_path = os.path.join(my_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels for the images\n",
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images in Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dictionary\n",
    "data = {\n",
    "    'Set': [],\n",
    "    'Label': [],\n",
    "    'Frequency': []\n",
    "}\n",
    "\n",
    "# Define dataset folders\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each dataset split and count images\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        path = os.path.join(my_data_dir, folder, label)\n",
    "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "        print(f\" {folder}/{label}: {num_images} images\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_freq = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart - Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.title(\"Image Distribution in Dataset\")\n",
    "plt.xlabel(\"Dataset Split\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow/Keras ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize ImageDataGenerator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation for Training Set\n",
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Training Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Validation Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Augmented Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Augmented Images in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images_grid(data_generator, num_images=10):\n",
    "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
    "    img_batch, label_batch = next(data_generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
    "        ax.imshow(img_batch[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image grid\n",
    "plot_augmented_images_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2 was chosen for its efficiency, speed, and strong feature extraction while maintaining high accuracy with fewer parameters. Its lightweight architecture makes it ideal for deployment in resource-constrained environments. Details are provided in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter\n",
    "learning_rate = 0.000075\n",
    "l2_lambda = 0.003\n",
    "dropout_rate = 0.35\n",
    "activation_function = \"relu\"\n",
    "patience_value = 6\n",
    "\n",
    "# Create Sigmoid CNN Model \n",
    "model_sigmoid = Sequential(\n",
    "    [\n",
    "        Input(shape=(128, 128, 3)),\n",
    "        Conv2D(16, (3, 3), activation=activation_function),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=activation_function),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=activation_function),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=activation_function, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation=\"sigmoid\"),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile Model\n",
    "model_sigmoid.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss=\"binary_crossentropy\",  \n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "model_sigmoid.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Start time tracking\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Set EarlyStopping & Learning Rate Scheduler\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", patience=patience_value, restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Sigmoid CNN Model\n",
    "history_sigmoid = model_sigmoid.fit(\n",
    "    train_set,  \n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sigmoid.save(\"outputs/v1/sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Loss Curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history_sigmoid.history[\"loss\"], \"o-\", label=\"Training Loss\")\n",
    "plt.plot(history_sigmoid.history[\"val_loss\"], \"o-\", label=\"Validation Loss\")\n",
    "plt.title(\"Loss Curve - Sigmoid CNN\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{output_dir}/loss_curve_sigmoid.png\", dpi=300)  \n",
    "plt.show()\n",
    "\n",
    "# Accuracy Curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history_sigmoid.history[\"accuracy\"], \"o-\", label=\"Training Accuracy\")\n",
    "plt.plot(history_sigmoid.history[\"val_accuracy\"], \"o-\", label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy Curve - Sigmoid CNN\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{output_dir}/accuracy_curve_sigmoid.png\", dpi=300)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves - Insights\n",
    "\n",
    "#### **Loss Curve**\n",
    "- The training and validation loss decrease smoothly, showing consistent learning.  \n",
    "- The validation loss stabilizes after a few epochs, indicating no major overfitting.  \n",
    "\n",
    "#### **Accuracy Curve**\n",
    "- Both training and validation accuracy steadily increase and converge near **99%**.  \n",
    "- This confirms strong generalization without signs of divergence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"outputs/v1/sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set, batch_size=batch_size)\n",
    "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
    "print(\"Model Loss: \", evaluation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Accuracy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly obtain true labels\n",
    "y_true = test_set.labels\n",
    "\n",
    "# Obtain model predictions\n",
    "preds = model.predict(test_set)\n",
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram below shows the overall distribution of model confidence scores for predictions on the test set. To explore individual image confidence levels and analyze misclassifications, please refer to the interactive version in the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_probs = model_sigmoid.predict(validation_set)\n",
    "\n",
    "# Compute Healthy and Infected probabilities\n",
    "df_probs = {\n",
    "    \"Healthy\": 1 - y_pred_probs[:, 0],  # Healthy probability\n",
    "    \"Infected\": y_pred_probs[:, 0],     # Infected probability\n",
    "}\n",
    "\n",
    "# Create histogram traces for both classes\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_probs[\"Healthy\"],\n",
    "        nbinsx=20,\n",
    "        opacity=0.6,\n",
    "        name=\"Healthy\",\n",
    "        marker_color=\"green\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_probs[\"Infected\"],\n",
    "        nbinsx=20,\n",
    "        opacity=0.6,\n",
    "        name=\"Infected\",\n",
    "        marker_color=\"blue\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add threshold line at 0.5\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5, 0.5],\n",
    "        y=[\n",
    "            0,\n",
    "            max(np.histogram(y_pred_probs[:, 0], bins=20)[0]),  # Adjust y-axis dynamically\n",
    "        ],\n",
    "        mode=\"lines\",\n",
    "        name=\"Threshold = 0.5\",\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Prediction Probability Histogram (Sigmoid Output)\",\n",
    "    xaxis_title=\"Prediction Probability\",\n",
    "    yaxis_title=\"Count\",\n",
    "    barmode=\"overlay\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "histogram_path = os.path.join(output_dir, \"histogram_test.png\")\n",
    "fig.write_image(histogram_path, scale=2)\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n",
    "\n",
    "print(f\"Histogram saved at: {histogram_path}\")\n",
    "\n",
    "# Cleanup Kaleido processes after saving the image\n",
    "def cleanup_kaleido():\n",
    "    for proc in psutil.process_iter([\"pid\", \"name\"]):\n",
    "        if \"kaleido\" in proc.info[\"name\"].lower():\n",
    "            os.kill(proc.info[\"pid\"], 9)  # Force kill\n",
    "\n",
    "\n",
    "cleanup_kaleido()  # Run cleanup to prevent zombie processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Probability Histogram - Insights\n",
    "\n",
    "- The predicted probabilities are strongly concentrated around **0 or 1**, indicating high model confidence.  \n",
    "- Minimal overlap between the two classes suggests that the decision boundary is well-defined.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import psutil\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get Class Labels\n",
    "label_map = list(test_set.class_indices.keys())\n",
    "\n",
    "# Evaluate Model on Train and Test Sets\n",
    "y_true_train = train_set.classes\n",
    "y_pred_train = (model_sigmoid.predict(train_set) >= 0.5).astype(int).flatten()\n",
    "\n",
    "y_true_test = test_set.classes\n",
    "y_pred_test = (model_sigmoid.predict(test_set) >= 0.5).astype(int).flatten()\n",
    "\n",
    "# Generate Confusion Matrices\n",
    "cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "\n",
    "# Convert confusion matrices to DataFrames\n",
    "df_cm_train = pd.DataFrame(cm_train, index=label_map, columns=label_map)\n",
    "df_cm_test = pd.DataFrame(cm_test, index=label_map, columns=label_map)\n",
    "\n",
    "\n",
    "# Function to create interactive Confusion Matrix\n",
    "def create_confusion_matrix_figure(conf_matrix, title):\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=conf_matrix.values,\n",
    "        x=conf_matrix.columns.tolist(),\n",
    "        y=conf_matrix.index.tolist(),\n",
    "        colorscale=\"Blues\",\n",
    "        showscale=True,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Predicted Label\",\n",
    "        yaxis_title=\"True Label\",\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create interactive plots\n",
    "fig_train = create_confusion_matrix_figure(df_cm_train, \"Confusion Matrix - Train Set\")\n",
    "fig_test = create_confusion_matrix_figure(df_cm_test, \"Confusion Matrix - Test Set\")\n",
    "\n",
    "# Save Figures\n",
    "fig_train.write_image(os.path.join(output_dir, \"confusion_matrix_train.png\"), scale=2)\n",
    "fig_test.write_image(os.path.join(output_dir, \"confusion_matrix_test.png\"), scale=2)\n",
    "\n",
    "fig_train.show()\n",
    "fig_test.show()\n",
    "\n",
    "print(\n",
    "    f\"Confusion Matrices saved at: {output_dir}/confusion_matrix_train.png & {output_dir}/confusion_matrix_test.png\"\n",
    ")\n",
    "\n",
    "\n",
    "# Cleanup Kaleido processes after saving the image\n",
    "def cleanup_kaleido():\n",
    "    for proc in psutil.process_iter([\"pid\", \"name\"]):\n",
    "        if \"kaleido\" in proc.info[\"name\"].lower():\n",
    "            os.kill(proc.info[\"pid\"], 9)  # Force kill\n",
    "\n",
    "\n",
    "cleanup_kaleido()  # Run cleanup to prevent zombie processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix - Insights\n",
    "\n",
    "- The **train set confusion matrix** shows a well-balanced classification, with very few misclassifications.  \n",
    "- The **test set confusion matrix** confirms strong generalization, as misclassification counts remain low, indicating that the model is not overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Generate classification reports as dictionaries\n",
    "report_train = classification_report(\n",
    "    y_true_train, y_pred_train, target_names=label_map, output_dict=True\n",
    ")\n",
    "report_test = classification_report(\n",
    "    y_true_test, y_pred_test, target_names=label_map, output_dict=True\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_train = pd.DataFrame(report_train).transpose().round(3)\n",
    "df_test = pd.DataFrame(report_test).transpose().round(3)\n",
    "\n",
    "# Print Train Report\n",
    "print(\"\\n### Classification Report - Train Set ###\\n\")\n",
    "print(df_train)\n",
    "\n",
    "# Print Test Report\n",
    "print(\"\\n### Classification Report - Test Set ###\\n\")\n",
    "print(df_test)\n",
    "\n",
    "# Save reports as CSV for future reference\n",
    "df_train.to_csv(f\"{output_dir}/classification_report_train.csv\")\n",
    "df_test.to_csv(f\"{output_dir}/classification_report_test.csv\")\n",
    "\n",
    "print(\n",
    "    f\"\\nReports saved to {output_dir}/classification_report_train.csv & {output_dir}/classification_report_test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report - Insights\n",
    "\n",
    "- The **train set classification report** shows a balanced precision, recall, and F1-score, indicating that the model effectively learns from training data.  \n",
    "- The **test set classification report** confirms strong generalization, with nearly identical metrics across both classes, ensuring reliable performance on unseen data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate predictions (probabilities)\n",
    "y_probs_train = model_sigmoid.predict(train_set).flatten()  # Convert to (num_samples,)\n",
    "y_probs_test = model_sigmoid.predict(test_set).flatten()  # Convert to (num_samples,)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_true_train, y_probs_train)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_true_test, y_probs_test)\n",
    "\n",
    "auc_train = auc(fpr_train, tpr_train)\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Create interactive ROC Curve using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Train ROC Curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr_train,\n",
    "        y=tpr_train,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Train AUC = {auc_train:.2f}\",\n",
    "        line=dict(color=\"blue\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Test ROC Curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr_test,\n",
    "        y=tpr_test,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Test AUC = {auc_test:.2f}\",\n",
    "        line=dict(color=\"green\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Random Guess Line (Baseline)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Random (AUC = 0.50)\",\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"ROC Curve - Train vs Test\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.7, y=0.2),\n",
    ")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "roc_curve_path = os.path.join(output_dir, \"roc_curve.png\")\n",
    "fig.write_image(roc_curve_path, scale=2)\n",
    "\n",
    "# Show interactive plot\n",
    "fig.show()\n",
    "\n",
    "print(f\"ROC Curve saved at: {roc_curve_path}\")\n",
    "\n",
    "\n",
    "# Cleanup Kaleido processes after saving the image\n",
    "def cleanup_kaleido():\n",
    "    for proc in psutil.process_iter([\"pid\", \"name\"]):\n",
    "        if \"kaleido\" in proc.info[\"name\"].lower():\n",
    "            os.kill(proc.info[\"pid\"], 9)  # Force kill\n",
    "\n",
    "\n",
    "cleanup_kaleido()  # Run cleanup to prevent zombie processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve - Insights\n",
    "\n",
    "- The **train ROC curve** demonstrates a high True Positive Rate (TPR) with minimal False Positive Rate (FPR), indicating strong discrimination ability.  \n",
    "- The **test ROC curve** closely follows the train curve, confirming that the model maintains high performance on unseen data without signs of overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance & Overfitting Analysis\n",
    "\n",
    "- The model achieved **99.64% accuracy** with a **low loss of 0.1486**, demonstrating strong performance.  \n",
    "- The **learning curves** confirm smooth convergence with no signs of major overfitting.  \n",
    "- The **confusion matrix and classification report** highlight minimal misclassification and high precision/recall.  \n",
    "- The **ROC curve** supports excellent class separation, ensuring the model generalizes well.  \n",
    "- Given these results, the model is **ready for deployment** with reliable predictive power.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Goal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results\n",
    "evaluation_results = joblib.load(\"outputs/v1/evaluation.pkl\")\n",
    "\n",
    "# Extract final test accuracy\n",
    "test_accuracy = evaluation_results[1]  \n",
    "\n",
    "# Check requirement\n",
    "accuracy_threshold = 0.90\n",
    "if test_accuracy >= accuracy_threshold:\n",
    "    print(f\"Model meets the business requirement! (Accuracy: {test_accuracy:.2%})\")\n",
    "else:\n",
    "    print(f\"Model does NOT meet the requirement. (Accuracy: {test_accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load random image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 66\n",
    "label = labels[0] \n",
    "pil_image = image.load_img(test_path + '/'+ label + '/'+ os.listdir(test_path+'/' + label)[pointer],\n",
    "                            target_size= image_shape, color_mode='rgb')\n",
    "\n",
    "print(f\" Image shape: {pil_image.size}, Image mode: {pil_image.mode}\")\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Image to Array and Prepare for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0) / 255.0  \n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0, 0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class = target_map[pred_proba < 0.5]\n",
    "\n",
    "if pred_class == target_map[1]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Record training duration\n",
    "end_time = time.time()\n",
    "training_time = round(end_time - start_time, 2)\n",
    "\n",
    "# Extract accuracy metrics from training history\n",
    "train_accuracy = round(history_sigmoid.history[\"accuracy\"][-1], 4)\n",
    "val_accuracy = round(history_sigmoid.history[\"val_accuracy\"][-1], 4)\n",
    "\n",
    "# Directly get test accuracy \n",
    "test_accuracy = (\n",
    "    round(test_accuracy, 4) if isinstance(test_accuracy, (int, float)) else None\n",
    ")\n",
    "\n",
    "# Measure inference time\n",
    "start_inf_time = time.time()\n",
    "model.predict(my_image)  # Run prediction on a sample image\n",
    "end_inf_time = time.time()\n",
    "\n",
    "# Calculate inference time per image\n",
    "inference_time = round((end_inf_time - start_inf_time), 4)\n",
    "\n",
    "# Determine overfitting risk\n",
    "overfitting_risk = \"Yes\" if train_accuracy - val_accuracy > 0.05 else \"No\"\n",
    "\n",
    "# Store results in a structured format\n",
    "results = {\n",
    "    \"Model\": \"Sigmoid\",\n",
    "    \"Training Accuracy\": train_accuracy,\n",
    "    \"Validation Accuracy\": val_accuracy,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Training Time (sec)\": training_time,\n",
    "    \"Inference Time (sec/sample)\": inference_time,\n",
    "    \"Batch Size\": 16,\n",
    "    \"Overfitting Risk\": overfitting_risk,\n",
    "}\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "df_results = pd.DataFrame([results])\n",
    "\n",
    "# Save results to CSV (append mode)\n",
    "csv_file = \"training_results.csv\"\n",
    "df_results.to_csv(\n",
    "    csv_file, mode=\"a\", index=False, header=not pd.io.common.file_exists(csv_file)\n",
    ")\n",
    "\n",
    "# Display results as a table\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We successfully developed a deep learning model for image classification using a structured, beginner-friendly approach.  \n",
    "\n",
    "### **Key Achievements**\n",
    "- **Explored Multiple Architectures** → Compared Sigmoid, Softmax, and MobileNetV2 across different trials.  \n",
    "- **Comprehensive Evaluation** → Assessed models using accuracy, loss, confusion matrices, and ROC curves.  \n",
    "- **Optimized for Generalization** → Selected the best-performing model with minimal overfitting.  \n",
    "- **Deployment-Ready Model** → Finalized MobileNetV2 for real-world application.  \n",
    "\n",
    "### **Next Steps: Model Deployment**\n",
    "- **Web App Integration** → Implement a user-friendly Streamlit interface for real-time image classification.  \n",
    "- **Model Deployment** → Load the trained model and deploy it on a cloud platform for accessibility.  \n",
    "\n",
    "This deployment will enable efficient real-world usage, making automated classification accessible to users.  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
