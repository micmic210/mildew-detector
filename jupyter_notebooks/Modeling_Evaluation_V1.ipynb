{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **SIGMOID Modeling and Evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
    "- Build and evaluate models: Implement a baseline CNN model, refine it through hyperparameter tuning, and assess performance.\n",
    "- Analyze model effectiveness: Use Saliency Maps and t-SNE visualization to interpret model predictions and feature separability.\n",
    "- Compare model performance: Select the best model based on accuracy, loss, and efficiency for real-world deployment.\n",
    "- Prepare for deployment: Save the optimized model for integration into a Streamlit web app hosted on Heroku.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Dataset\n",
    "- inputs/mildew_dataset/cherry-leaves/train\n",
    "- inputs/mildew_dataset/cherry-leaves/validation\n",
    "- inputs/mildew_dataset/cherry-leaves/test\n",
    "\n",
    "Precomputed Features (from Data Visualization Notebook)\n",
    "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
    "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
    "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Data Processing & Visualization\n",
    "- Dataset Distribution Plot → Confirmed balanced data split across training, validation, and test sets.\n",
    "- Data Augmentation Visualization → Showcased applied transformations, including rotation, flipping, and zooming.\n",
    "Model Training & Optimization\n",
    "- Baseline CNN Model → Implemented a standard CNN to establish initial performance.\n",
    "- Hyperparameter-Tuned CNN → Optimized model performance using Keras Tuner (adjusting filters, dropout, learning rate, and L2 regularization).\n",
    "- Best Model Selection → Chose the Tuned CNN based on test accuracy and generalization ability.\n",
    "- Saved Trained Models → Final model stored for Streamlit integration and deployment on Heroku.\n",
    "Model Evaluation & Explainability\n",
    "- Learning Curves → Visualized loss and accuracy trends over epochs.\n",
    "- Confusion Matrices → Displayed classification performance for train, validation, and test sets.\n",
    "- Classification Reports → Provided precision, recall, and F1-score analysis.\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "- Business Impact: The trained model can assist in early detection of powdery mildew, reducing manual inspection time and improving plantation monitoring efficiency.\n",
    "- Data-Driven Enhancements: Model improvements were guided by data preprocessing insights, including class balance validation.\n",
    "- Deployment Readiness: The best model was optimized and prepared for integration into a Streamlit web app for real-world application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/mildew-detector')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "#### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "## Set Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directories\n",
    "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
    "train_path = os.path.join(my_data_dir, 'train')\n",
    "val_path = os.path.join(my_data_dir, 'validation')\n",
    "test_path = os.path.join(my_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels for the images\n",
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images in Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dictionary\n",
    "data = {\n",
    "    'Set': [],\n",
    "    'Label': [],\n",
    "    'Frequency': []\n",
    "}\n",
    "\n",
    "# Define dataset folders\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each dataset split and count images\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        path = os.path.join(my_data_dir, folder, label)\n",
    "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "        print(f\" {folder}/{label}: {num_images} images\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_freq = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart - Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.title(\"Image Distribution in Dataset\")\n",
    "plt.xlabel(\"Dataset Split\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow/Keras ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize ImageDataGenerator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation for Training Set\n",
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Training Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Validation Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Augmented Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Augmented Images in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images_grid(data_generator, num_images=10):\n",
    "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
    "    img_batch, label_batch = next(data_generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
    "        ax.imshow(img_batch[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image grid\n",
    "plot_augmented_images_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input  \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, a Convolutional Neural Network (CNN) was selected because it is highly effective for image classification tasks. Unlike traditional machine learning models, CNNs can automatically learn hierarchical spatial features from images, making them ideal for detecting powdery mildew in cherry leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cnn():\n",
    "    \"\"\"\n",
    "    Builds a simple, lightweight CNN for binary classification (Sigmoid output).\n",
    "    Designed as a baseline model with minimal hyperparameter tuning.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): A compiled Keras CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            # Input Layer\n",
    "            Input(shape=(128, 128, 3)),\n",
    "            # Feature Extraction Blocks\n",
    "            Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Flatten and Fully Connected Layers\n",
    "            Flatten(),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dropout(0.3),  # Basic dropout for regularization\n",
    "            # Output Layer (Binary Classification)\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile Model (Moderate Learning Rate for Stability)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base CNN model\n",
    "model_base_cnn = create_base_cnn()\n",
    "\n",
    "# Print model summary\n",
    "model_base_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set EarlyStopping callback\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit CNN Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "model_base_cnn = create_base_cnn()\n",
    "\n",
    "# Train the base CNN model\n",
    "history_base_cnn = model_base_cnn.fit(\n",
    "    train_set,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained base CNN model\n",
    "model_base_cnn.save(\"outputs/v1/mildew_detector_base_cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Base CNN on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the base CNN model\n",
    "test_loss_base_cnn, test_accuracy_base_cnn = model_base_cnn.evaluate(test_set)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Test Accuracy (Base CNN): {test_accuracy_base_cnn:.4f}\")\n",
    "print(f\"Test Loss (Base CNN): {test_loss_base_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training History for Base CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training history of Base CNN to DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df_history_base_cnn = pd.DataFrame(history_base_cnn.history)\n",
    "\n",
    "# Save history for later use\n",
    "df_history_base_cnn.to_csv(\"outputs/v1/history_base_cnn.csv\", index=False)\n",
    "print(\"Base CNN training history saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning Curve for Base CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot Loss Curve\n",
    "df_history_base_cnn[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy Curve\n",
    "df_history_base_cnn[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/model_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def generate_confusion_matrices(y_train, y_train_pred, y_test, y_test_pred, label_map):\n",
    "    \"\"\"\n",
    "    Generates and displays side-by-side confusion matrices for Train and Test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - y_train: Actual train labels\n",
    "    - y_train_pred: Predicted train labels\n",
    "    - y_test: Actual test labels\n",
    "    - y_test_pred: Predicted test labels\n",
    "    - label_map: List of class names\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # Side-by-side plots\n",
    "\n",
    "    # Train Confusion Matrix\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(cm_train, index=label_map, columns=label_map),\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        linewidths=0.5,\n",
    "        ax=axes[0],\n",
    "    )\n",
    "    axes[0].set_title(\"Confusion Matrix - Train Set\")\n",
    "    axes[0].set_xlabel(\"Predicted Label\")\n",
    "    axes[0].set_ylabel(\"True Label\")\n",
    "\n",
    "    # Test Confusion Matrix\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(cm_test, index=label_map, columns=label_map),\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        linewidths=0.5,\n",
    "        ax=axes[1],\n",
    "    )\n",
    "    axes[1].set_title(\"Confusion Matrix - Test Set\")\n",
    "    axes[1].set_xlabel(\"Predicted Label\")\n",
    "    axes[1].set_ylabel(\"True Label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show confusion matrix\n",
    "    save_path = os.path.join(output_dir, \"confusion_matrices_train_test.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"Confusion Matrices saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_reports(\n",
    "    y_train, y_train_pred, y_test, y_test_pred, label_map\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates and saves classification reports for Train and Test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - y_train: Actual train labels\n",
    "    - y_train_pred: Predicted train labels\n",
    "    - y_test: Actual test labels\n",
    "    - y_test_pred: Predicted test labels\n",
    "    - label_map: List of class names\n",
    "    \"\"\"\n",
    "    report_train = classification_report(y_train, y_train_pred, target_names=label_map)\n",
    "    report_test = classification_report(y_test, y_test_pred, target_names=label_map)\n",
    "\n",
    "    print(\"\\n--- Classification Report: Train Set ---\\n\")\n",
    "    print(report_train)\n",
    "    print(\"\\n--- Classification Report: Test Set ---\\n\")\n",
    "    print(report_test)\n",
    "\n",
    "    # Save reports as text files\n",
    "    report_train_path = os.path.join(output_dir, \"classification_report_train.txt\")\n",
    "    report_test_path = os.path.join(output_dir, \"classification_report_test.txt\")\n",
    "\n",
    "    with open(report_train_path, \"w\") as f:\n",
    "        f.write(report_train)\n",
    "    with open(report_test_path, \"w\") as f:\n",
    "        f.write(report_test)\n",
    "\n",
    "    print(f\"Classification reports saved at: {report_train_path} & {report_test_path}\")\n",
    "\n",
    "\n",
    "def evaluate_model(train_generator, test_generator, model, label_map, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluates model performance by generating confusion matrices and classification reports.\n",
    "\n",
    "    Parameters:\n",
    "    - train_generator: Training set generator\n",
    "    - test_generator: Test set generator\n",
    "    - model: Trained model\n",
    "    - label_map: List of class names\n",
    "    - threshold: Probability threshold for classification (default: 0.5)\n",
    "    \"\"\"\n",
    "    y_train = train_generator.classes  # True labels for training set\n",
    "    y_test = test_generator.classes  # True labels for test set\n",
    "\n",
    "    y_train_probs = model.predict(train_generator)  # Model predictions for train set\n",
    "    y_test_probs = model.predict(test_generator)  # Model predictions for test set\n",
    "\n",
    "    y_train_pred = (\n",
    "        (y_train_probs > threshold).astype(int).flatten()\n",
    "    )  # Convert to class labels\n",
    "    y_test_pred = (\n",
    "        (y_test_probs > threshold).astype(int).flatten()\n",
    "    )  # Convert to class labels\n",
    "\n",
    "    print(\"\\n#### Model Evaluation ####\\n\")\n",
    "\n",
    "    # Generate side-by-side confusion matrices\n",
    "    generate_confusion_matrices(y_train, y_train_pred, y_test, y_test_pred, label_map)\n",
    "\n",
    "    # Generate and save classification reports\n",
    "    generate_classification_reports(\n",
    "        y_train, y_train_pred, y_test, y_test_pred, label_map\n",
    "    )\n",
    "\n",
    "\n",
    "# Get class labels from training set\n",
    "label_map = list(train_set.class_indices.keys())\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(train_set, test_set, model_base_cnn, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Probability Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"inputs/mildew_dataset/cherry-leaves/\"\n",
    "\n",
    "# Create ImageDataGenerator for test set\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load test dataset\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=os.path.join(dataset_path, \"test\"),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Load the Sigmoid CNN model\n",
    "model_sigmoid = load_model(\"outputs/v1/mildew_detector_base_cnn.h5\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_probs = model_sigmoid.predict(test_generator).flatten()\n",
    "\n",
    "# Get actual labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Define class labels\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Separate probabilities based on true labels\n",
    "y_probs_healthy = y_probs[y_true == 0]  # Healthy (Class 0)\n",
    "y_probs_infected = y_probs[y_true == 1]  # Infected (Class 1)\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Histogram for each class\n",
    "sns.histplot(\n",
    "    y_probs_healthy,\n",
    "    bins=20,\n",
    "    kde=True,\n",
    "    color=\"green\",\n",
    "    alpha=0.6,\n",
    "    label=\"Healthy (Class 0)\",\n",
    ")\n",
    "sns.histplot(\n",
    "    y_probs_infected,\n",
    "    bins=20,\n",
    "    kde=True,\n",
    "    color=\"blue\",\n",
    "    alpha=0.6,\n",
    "    label=\"Infected (Class 1)\",\n",
    ")\n",
    "\n",
    "# Add threshold line\n",
    "plt.axvline(x=0.5, color=\"red\", linestyle=\"dashed\", label=\"Threshold = 0.5\")\n",
    "\n",
    "# Title & labels\n",
    "plt.title(\"Prediction Probability Histogram - Test Set (Sigmoid CNN)\", fontsize=12)\n",
    "plt.xlabel(\"Predicted Probability\", fontsize=10)\n",
    "plt.ylabel(\"Frequency\", fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Save histogram\n",
    "hist_path = \"outputs/v1/histogram_sigmoid.png\"\n",
    "plt.savefig(hist_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Histogram saved at: {hist_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store evaluation results with the correct variable names\n",
    "evaluation = {\n",
    "    \"test_loss\": test_loss_base_cnn, \n",
    "    \"test_accuracy\": test_accuracy_base_cnn\n",
    "}\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save evaluation results\n",
    "joblib.dump(value=evaluation, filename=\"outputs/v1/evaluation_base_cnn.pkl\")\n",
    "print(\"\\nModel evaluation results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "| **Hyperparameter**        | **Current Value** | **Updated Value** | **Reason for Change** |\n",
    "|-------------------------|---------------|----------------------|----------------|\n",
    "| **Dropout**             | `0.3`           | Reduce in early layers, increase in FC layers (`0.3 → 0.5`) | Avoid excessive early regularization while ensuring final FC layers don’t overfit |\n",
    "| **Batch Normalization** | `None`          | Add after `Conv2D` layers | Stabilizes training and ensures better feature scaling |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sig_tuned():\n",
    "    \"\"\"\n",
    "    Updated CNN with Batch Normalization and improved Dropout placement.\n",
    "    \"\"\"\n",
    "    model = Sequential(\n",
    "        [\n",
    "            # Input Layer\n",
    "            Input(shape=(128, 128, 3)),\n",
    "            # Feature Extraction Blocks\n",
    "            Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Flatten and Fully Connected Layers\n",
    "            Flatten(),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dropout(0.),  \n",
    "            # Output Layer (Binary Classification)\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base CNN model\n",
    "model_sig_tuned = create_sig_tuned()\n",
    "\n",
    "# Print model summary\n",
    "model_sig_tuned.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set EarlyStopping callback\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Tuned Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the base CNN model\n",
    "history_sig_tuned = model_sig_tuned.fit(\n",
    "    train_set,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sig_tuned.save(\"outputs/v1/mildew_detector_sig_tuned.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Tuned Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tuned Sigmoind model\n",
    "test_loss_base_cnn, test_accuracy_base_cnn = model_sig_tuned.evaluate(test_set)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Test Accuracy (Base CNN): {test_accuracy_base_cnn:.4f}\")\n",
    "print(f\"Test Loss (Base CNN): {test_loss_base_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Training History to DataFrame (Tuned CNN)\n",
    "import pandas as pd\n",
    "\n",
    "df_history_sig_tuned = pd.DataFrame(history_sig_tuned.history)\n",
    "\n",
    "# Save history for later use\n",
    "df_history_sig_tuned.to_csv(\"outputs/v1/history_sig_tuned.csv\", index=False)\n",
    "print(\"Sig Tuned CNN training history saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot Loss Curve\n",
    "df_history_sig_tuned[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/model_training_losses_sig_tuned.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy Curve\n",
    "df_history_sig_tuned[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/model_training_acc_sig_tuned.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def generate_confusion_matrices(y_train, y_train_pred, y_test, y_test_pred, label_map):\n",
    "    \"\"\"\n",
    "    Generates and displays a side-by-side confusion matrix for Train and Test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - y_train: Actual train labels\n",
    "    - y_train_pred: Predicted train labels\n",
    "    - y_test: Actual test labels\n",
    "    - y_test_pred: Predicted test labels\n",
    "    - label_map: List of class names\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # Side-by-side plots\n",
    "\n",
    "    # Train Confusion Matrix\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(cm_train, index=label_map, columns=label_map),\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        linewidths=0.5,\n",
    "        ax=axes[0],\n",
    "    )\n",
    "    axes[0].set_title(\"Confusion Matrix - Train Set\")\n",
    "    axes[0].set_xlabel(\"Predicted Label\")\n",
    "    axes[0].set_ylabel(\"True Label\")\n",
    "\n",
    "    # Test Confusion Matrix\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(cm_test, index=label_map, columns=label_map),\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        linewidths=0.5,\n",
    "        ax=axes[1],\n",
    "    )\n",
    "    axes[1].set_title(\"Confusion Matrix - Test Set\")\n",
    "    axes[1].set_xlabel(\"Predicted Label\")\n",
    "    axes[1].set_ylabel(\"True Label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show confusion matrix\n",
    "    save_path = os.path.join(output_dir, \"confusion_matrices_train_test.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"Confusion Matrices saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_reports(\n",
    "    y_train, y_train_pred, y_test, y_test_pred, label_map\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates and saves classification reports for Train and Test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - y_train: Actual train labels\n",
    "    - y_train_pred: Predicted train labels\n",
    "    - y_test: Actual test labels\n",
    "    - y_test_pred: Predicted test labels\n",
    "    - label_map: List of class names\n",
    "    \"\"\"\n",
    "    report_train = classification_report(y_train, y_train_pred, target_names=label_map)\n",
    "    report_test = classification_report(y_test, y_test_pred, target_names=label_map)\n",
    "\n",
    "    print(\"\\n--- Classification Report: Train Set ---\\n\")\n",
    "    print(report_train)\n",
    "    print(\"\\n--- Classification Report: Test Set ---\\n\")\n",
    "    print(report_test)\n",
    "\n",
    "    # Save reports as text files\n",
    "    report_train_path = os.path.join(output_dir, \"classification_report_train.txt\")\n",
    "    report_test_path = os.path.join(output_dir, \"classification_report_test.txt\")\n",
    "\n",
    "    with open(report_train_path, \"w\") as f:\n",
    "        f.write(report_train)\n",
    "    with open(report_test_path, \"w\") as f:\n",
    "        f.write(report_test)\n",
    "\n",
    "    print(f\"Classification reports saved at: {report_train_path} & {report_test_path}\")\n",
    "\n",
    "\n",
    "def evaluate_model(train_generator, test_generator, model, label_map, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluates model performance by generating confusion matrices and classification reports.\n",
    "\n",
    "    Parameters:\n",
    "    - train_generator: Training set generator\n",
    "    - test_generator: Test set generator\n",
    "    - model: Trained model\n",
    "    - label_map: List of class names\n",
    "    - threshold: Probability threshold for classification (default: 0.5)\n",
    "    \"\"\"\n",
    "    y_train = train_generator.classes  # True labels for training set\n",
    "    y_test = test_generator.classes  # True labels for test set\n",
    "\n",
    "    y_train_probs = model.predict(train_generator)  # Model predictions for train set\n",
    "    y_test_probs = model.predict(test_generator)  # Model predictions for test set\n",
    "\n",
    "    y_train_pred = (\n",
    "        (y_train_probs > threshold).astype(int).flatten()\n",
    "    )  # Convert to class labels\n",
    "    y_test_pred = (\n",
    "        (y_test_probs > threshold).astype(int).flatten()\n",
    "    )  # Convert to class labels\n",
    "\n",
    "    print(\"\\n#### Model Evaluation ####\\n\")\n",
    "\n",
    "    # Generate side-by-side confusion matrices\n",
    "    generate_confusion_matrices(y_train, y_train_pred, y_test, y_test_pred, label_map)\n",
    "\n",
    "    # Generate and save classification reports\n",
    "    generate_classification_reports(\n",
    "        y_train, y_train_pred, y_test, y_test_pred, label_map\n",
    "    )\n",
    "\n",
    "\n",
    "# Get class labels from training set\n",
    "label_map = list(train_set.class_indices.keys())\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(train_set, test_set, model_base_cnn, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Probability Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"inputs/mildew_dataset/cherry-leaves/\"\n",
    "\n",
    "# Create ImageDataGenerator for test set\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load test dataset\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=os.path.join(dataset_path, \"test\"),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Load the Sigmoid CNN model\n",
    "model_sigmoid = load_model(\"outputs/v1/mildew_detector_sig_tuned.h5\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_probs = model_sigmoid.predict(test_generator).flatten()\n",
    "\n",
    "# Get actual labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Define class labels\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Separate probabilities based on true labels\n",
    "y_probs_healthy = y_probs[y_true == 0]  # Healthy (Class 0)\n",
    "y_probs_infected = y_probs[y_true == 1]  # Infected (Class 1)\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Histogram for each class\n",
    "sns.histplot(\n",
    "    y_probs_healthy,\n",
    "    bins=20,\n",
    "    kde=True,\n",
    "    color=\"green\",\n",
    "    alpha=0.6,\n",
    "    label=\"Healthy (Class 0)\",\n",
    ")\n",
    "sns.histplot(\n",
    "    y_probs_mildew,\n",
    "    bins=20,\n",
    "    kde=True,\n",
    "    color=\"blue\",\n",
    "    alpha=0.6,\n",
    "    label=\"Infected (Class 1)\",\n",
    ")\n",
    "\n",
    "# Add threshold line\n",
    "plt.axvline(x=0.5, color=\"red\", linestyle=\"dashed\", label=\"Threshold = 0.5\")\n",
    "\n",
    "# Title & labels\n",
    "plt.title(\"Prediction Probability Histogram - Test Set (Sigmoid CNN)\", fontsize=12)\n",
    "plt.xlabel(\"Predicted Probability\", fontsize=10)\n",
    "plt.ylabel(\"Frequency\", fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Save histogram\n",
    "hist_path = \"outputs/v1/histogram_tuned_sigmoid.png\"\n",
    "plt.savefig(hist_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Histogram saved at: {hist_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store evaluation results with the correct variable names for the tuned Sigmoid model\n",
    "evaluation_sig_tuned = {\n",
    "    \"test_loss\": test_loss_base_cnn, \n",
    "    \"test_accuracy\": test_accuracy_base_cnn\n",
    "}\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save evaluation results for the tuned Sigmoid model\n",
    "joblib.dump(value=evaluation_sig_tuned, filename=\"outputs/v1/evaluation_sig_tuned.pkl\")\n",
    "print(\"\\nTuned Sigmoid model evaluation results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison & Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Both Models and Training Histories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "# Load Base CNN Model\n",
    "base_cnn_model = load_model(\"outputs/v1/mildew_detector_base_cnn.keras\")\n",
    "\n",
    "# Load Tuned CNN Model\n",
    "tuned_cnn_model = load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
    "\n",
    "# Load Training Histories\n",
    "history_base = pd.read_csv(\"outputs/v1/history_base_cnn.csv\")\n",
    "history_tuned = pd.read_csv(\"outputs/v1/history_tuned_cnn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Accuracy & Loss Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure correct variable names are used\n",
    "models = [\"Base CNN\", \"Tuned CNN\"]\n",
    "accuracy_values = [test_accuracy_base_cnn, test_accuracy_tuned]\n",
    "loss_values = [test_loss_base_cnn, test_loss_tuned]\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "\n",
    "# Plot Accuracy Comparison\n",
    "ax[0].bar(models, accuracy_values, color=[\"blue\", \"green\"])\n",
    "ax[0].set_ylabel(\"Test Accuracy\")\n",
    "ax[0].set_title(\"Accuracy Comparison: Base CNN vs. Tuned CNN\")\n",
    "ax[0].set_ylim(0, 1)  # Ensure accuracy is within [0,1]\n",
    "ax[0].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Fix warning by setting ticks first\n",
    "ax[0].set_xticks(range(len(models)))\n",
    "ax[0].set_xticklabels([f\"{models[i]} ({accuracy_values[i]:.4f})\" for i in range(len(models))])\n",
    "\n",
    "# Plot Loss Comparison\n",
    "ax[1].bar(models, loss_values, color=[\"red\", \"purple\"])\n",
    "ax[1].set_ylabel(\"Test Loss\")\n",
    "ax[1].set_title(\"Loss Comparison: Base CNN vs. Tuned CNN\")\n",
    "ax[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Fix warning by setting ticks first\n",
    "ax[1].set_xticks(range(len(models)))\n",
    "ax[1].set_xticklabels([f\"{models[i]} ({loss_values[i]:.4f})\" for i in range(len(models))])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Metrics (Accuracy, Precision, Recall, F1-Score, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Get true labels from test set\n",
    "y_true = test_set.classes  # Works if using ImageDataGenerator\n",
    "\n",
    "# Get model predictions (convert probabilities to binary)\n",
    "y_pred_base = (base_cnn_model.predict(test_set) > 0.5).astype(\"int32\").flatten()\n",
    "y_pred_tuned = (tuned_cnn_model.predict(test_set) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Get probability predictions for AUC\n",
    "y_pred_base_prob = base_cnn_model.predict(test_set).flatten()\n",
    "y_pred_tuned_prob = tuned_cnn_model.predict(test_set).flatten()\n",
    "\n",
    "# Compute Accuracy, Precision, Recall, F1-score\n",
    "report_base = classification_report(y_true, y_pred_base, output_dict=True)\n",
    "report_tuned = classification_report(y_true, y_pred_tuned, output_dict=True)\n",
    "\n",
    "# Compute AUC Score\n",
    "auc_base = roc_auc_score(y_true, y_pred_base_prob)\n",
    "auc_tuned = roc_auc_score(y_true, y_pred_tuned_prob)\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n### Base CNN Evaluation ###\")\n",
    "print(f\"Test Accuracy: {report_base['accuracy']:.4f}\")\n",
    "print(f\"Precision: {report_base['1']['precision']:.4f}\")\n",
    "print(f\"Recall: {report_base['1']['recall']:.4f}\")\n",
    "print(f\"F1-score: {report_base['1']['f1-score']:.4f}\")\n",
    "print(f\"AUC Score: {auc_base:.4f}\")\n",
    "\n",
    "print(\"\\n### Tuned CNN Evaluation ###\")\n",
    "print(f\"Test Accuracy: {report_tuned['accuracy']:.4f}\")\n",
    "print(f\"Precision: {report_tuned['1']['precision']:.4f}\")\n",
    "print(f\"Recall: {report_tuned['1']['recall']:.4f}\")\n",
    "print(f\"F1-score: {report_tuned['1']['f1-score']:.4f}\")\n",
    "print(f\"AUC Score: {auc_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Best Model & Save It for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on AUC score\n",
    "best_model = tuned_cnn_model if auc_tuned > auc_base else base_cnn_model\n",
    "best_model_name = \"Tuned CNN\" if auc_tuned > auc_base else \"Base CNN\"\n",
    "\n",
    "# Save the best model for deployment\n",
    "best_model.save(\"outputs/v1/final_mildew_detector.keras\")\n",
    "\n",
    "print(\"\\n### Best Model Selected & Saved ###\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(\"Model saved as 'final_mildew_detector.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Predict on Sample Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the final trained model\n",
    "model = load_model(\"outputs/v1/final_mildew_detector.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Load a Random Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Define test image selection parameters\n",
    "pointer = 60  # Change this number to select a different image\n",
    "label = labels[1]  # Select \"Healthy\" (0) or \"Infected\" (1)\n",
    "\n",
    "# Load the image using PIL\n",
    "img_path = test_path + \"/\" + label + \"/\" + os.listdir(test_path + \"/\" + label)[pointer]\n",
    "pil_image = image.load_img(img_path, target_size=image_shape, color_mode=\"rgb\")\n",
    "\n",
    "# Display image details\n",
    "print(f\"Selected Image Path: {img_path}\")\n",
    "print(f\"Image shape: {pil_image.size}, Image mode: {pil_image.mode}\")\n",
    "\n",
    "# Show the image\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction & Display Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "pred_proba = model.predict(my_image)[0, 0]  # Extract single probability score\n",
    "\n",
    "# Map indices to class labels\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}  # Reverse mapping\n",
    "pred_class = target_map[int(pred_proba > 0.5)]  # Ensure correct label mapping\n",
    "\n",
    "# Adjust probability if necessary\n",
    "if pred_class == target_map[0]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "# Print prediction results\n",
    "print(f\"Predicted Class: {pred_class}\")\n",
    "print(f\"Prediction Probability: {pred_proba:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we successfully developed a deep learning model to detect Powdery Mildew on Cherry Leaves using a structured, beginner-friendly approach.\n",
    "\n",
    "## Key Achievements\n",
    "- Baseline CNN Implementation → Developed an initial CNN model to establish a performance benchmark.\n",
    "- Optimized Hyperparameter Tuning → Applied systematic tuning (adjusting filters, dropout, learning rate, and L2 regularization) to enhance model performance while balancing computational efficiency.\n",
    "- Model Evaluation & Comparison → Assessed the baseline and optimized CNN models based on accuracy, loss, and generalization ability.\n",
    "- Explainability with Saliency Maps → Visualized important regions influencing the model’s predictions, enhancing interpretability.\n",
    "- Final Model Selection → The Hyperparameter-Tuned CNN was chosen based on its superior accuracy and robustness for real-world deployment.\n",
    "\n",
    "## Next Steps: Model Deployment\n",
    "\n",
    "The next step is to integrate the optimized CNN model into a user-friendly application that allows real-time classification of leaf images.\n",
    "\n",
    "Deployment Plan\n",
    "- Develop an Interactive Web App → Implement a Streamlit-based interface where users can upload leaf images for classification.\n",
    "- Integrate the Tuned CNN Model → Load the trained model to process new images and predict mildew presence.\n",
    "- Deploy on a Cloud Platform → Host the web application using Streamlit and Heroku for accessibility.\n",
    "\n",
    "This deployment will enable real-time detection of powdery mildew, aiding efficient disease monitoring and automated plantation management.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
