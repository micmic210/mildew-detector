{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Modeling and Evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Dataset\n",
    "- inputs/mildew_dataset/cherry-leaves/train\n",
    "- inputs/mildew_dataset/cherry-leaves/validation\n",
    "- inputs/mildew_dataset/cherry-leaves/test\n",
    "\n",
    "Precomputed Features (from Data Visualization Notebook)\n",
    "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
    "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
    "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "### Data Processing & Visualization\n",
    "- **Dataset Distribution Plot** → Confirms balanced data split across training, validation, and test sets.  \n",
    "- **Data Augmentation Visualization** → Showcases applied transformations (rotation, flipping, zooming).  \n",
    "\n",
    "### Model Training & Evaluation\n",
    "- **Baseline CNN Models (Sigmoid & Softmax)** → Initial experiments to establish a benchmark.  \n",
    "- **MobileNetV2 Fine-Tuning** → Explored optimized architectures with different hyperparameters.  \n",
    "- **Best Model Selection** → Chose the most balanced model based on test accuracy, generalization, and robustness.  \n",
    "- **Saved Trained Model** → Final MobileNetV2 model stored for deployment.  \n",
    "\n",
    "### Model Performance & Explainability\n",
    "- **Learning Curves** → Visualizes loss and accuracy trends over epochs.  \n",
    "- **Histograms** → Displays predicted probability distributions.  \n",
    "- **Overfitting & Generalization Check** → Assesses potential overfitting using accuracy and loss gaps.  \n",
    "- **Confusion Matrices** → Shows classification performance for train, validation, and test sets.  \n",
    "- **Classification Reports** → Provides precision, recall, and F1-score analysis.  \n",
    "- **ROC Curves** → Evaluates model performance using Receiver Operating Characteristic analysis.  \n",
    "- **Business Goal Validation** → Confirms if the model meets the required accuracy threshold.  \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "- **Business Impact:** Enables early detection of powdery mildew, reducing manual inspection and improving monitoring.  \n",
    "- **Data-Driven Improvements:** Model refinements were based on data insights, ensuring balanced class distribution.  \n",
    "- **Deployment:** The optimized model is ready for Streamlit integration for real-world use.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/workspaces/mildew-detector\")\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "#### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "## Set Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directories\n",
    "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
    "train_path = os.path.join(my_data_dir, 'train')\n",
    "val_path = os.path.join(my_data_dir, 'validation')\n",
    "test_path = os.path.join(my_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels for the images\n",
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images in Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dictionary\n",
    "data = {\n",
    "    'Set': [],\n",
    "    'Label': [],\n",
    "    'Frequency': []\n",
    "}\n",
    "\n",
    "# Define dataset folders\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each dataset split and count images\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        path = os.path.join(my_data_dir, folder, label)\n",
    "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "        print(f\" {folder}/{label}: {num_images} images\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_freq = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart - Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.title(\"Image Distribution in Dataset\")\n",
    "plt.xlabel(\"Dataset Split\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow/Keras ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize ImageDataGenerator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation for Training Set\n",
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Training Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Validation Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Augmented Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Augmented Images in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images_grid(data_generator, num_images=10):\n",
    "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
    "    img_batch, label_batch = next(data_generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
    "        ax.imshow(img_batch[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image grid\n",
    "plot_augmented_images_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2 was chosen for its efficiency, speed, and strong feature extraction while maintaining high accuracy with fewer parameters. Its lightweight architecture makes it ideal for deployment in resource-constrained environments. Details are provided in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter combination\n",
    "learning_rate = 0.00005\n",
    "l2_lambda = 0.003\n",
    "dropout_rate = 0.4\n",
    "activation_function = \"tanh\"\n",
    "patience_value = 3\n",
    "\n",
    "# Create Softmax CNN Model\n",
    "model_softmax = Sequential(\n",
    "    [\n",
    "        Input(shape=(128, 128, 3)),\n",
    "        Conv2D(16, (3, 3), activation=activation_function),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=activation_function),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=activation_function),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=activation_function, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile Model\n",
    "model_softmax.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "model_softmax.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Start time tracking \n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Set EarlyStopping & Learning Rate Scheduler\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", patience=patience_value, restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Softmax CNN Model\n",
    "history_softmax = model_softmax.fit(\n",
    "    train_set,  \n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax.save(\"outputs/v1/softmax.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Loss Curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history_softmax.history[\"loss\"], \"o-\", label=\"Training Loss\")\n",
    "plt.plot(history_softmax.history[\"val_loss\"], \"o-\", label=\"Validation Loss\")\n",
    "plt.title(\"Loss Curve - Softmax CNN\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{output_dir}/loss_curve_softmax.png\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history_softmax.history[\"accuracy\"], \"o-\", label=\"Training Accuracy\")\n",
    "plt.plot(history_softmax.history[\"val_accuracy\"], \"o-\", label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy Curve - Softmax CNN\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{output_dir}/accuracy_curve_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves - Insights\n",
    "\n",
    "#### **Loss Curve**\n",
    "- The training and validation loss decrease smoothly, showing consistent learning.  \n",
    "- The validation loss stabilizes after a few epochs, indicating no major overfitting.  \n",
    "\n",
    "#### **Accuracy Curve**\n",
    "- Both training and validation accuracy steadily increase and converge near **99%**.  \n",
    "- This confirms strong generalization without signs of divergence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"outputs/v1/softmax.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set, batch_size=batch_size)\n",
    "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
    "print(\"Model Loss: \", evaluation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Accuracy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly obtain true labels\n",
    "y_true = test_set.labels\n",
    "\n",
    "# Obtain model predictions\n",
    "preds = model.predict(test_set)\n",
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram below shows the overall distribution of model confidence scores for predictions on the test set. To explore individual image confidence levels and analyze misclassifications, please refer to the interactive version in the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_probs = model_softmax.predict(validation_set)\n",
    "\n",
    "# Extract class probabilities from Softmax output\n",
    "healthy_probs = y_pred_probs[:, 0]  # Probability of Healthy class\n",
    "infected_probs = y_pred_probs[:, 1]  # Probability of Infected class\n",
    "\n",
    "# Create static histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(healthy_probs, bins=20, alpha=0.6, color=\"green\", label=\"Healthy\")\n",
    "plt.hist(infected_probs, bins=20, alpha=0.6, color=\"blue\", label=\"Infected\")\n",
    "\n",
    "# Add threshold line at 0.5\n",
    "plt.axvline(x=0.5, color=\"red\", linestyle=\"dashed\", label=\"Threshold = 0.5\")\n",
    "\n",
    "plt.title(\"Prediction Probability Histogram\")\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Define file path\n",
    "histogram_path = os.path.join(output_dir, \"histogram_test.png\")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "plt.savefig(histogram_path, dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "# Show the static plot in the notebook\n",
    "plt.show()\n",
    "\n",
    "print(f\"Histogram saved at: {histogram_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Probability Histogram - Insights\n",
    "\n",
    "- The predicted probabilities are strongly concentrated around **0 or 1**, indicating high model confidence.  \n",
    "- Minimal overlap between the two classes suggests that the decision boundary is well-defined.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get Class Labels\n",
    "label_map = list(test_set.class_indices.keys())\n",
    "\n",
    "# Evaluate Model on Train and Test Sets\n",
    "y_true_train = train_set.classes\n",
    "y_pred_train = np.argmax(model_softmax.predict(train_set), axis=1)\n",
    "\n",
    "y_true_test = test_set.classes\n",
    "y_pred_test = np.argmax(model_softmax.predict(test_set), axis=1)\n",
    "\n",
    "# Generate Confusion Matrices for Train and Test Sets\n",
    "cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "\n",
    "# Convert confusion matrices to DataFrames\n",
    "df_cm_train = pd.DataFrame(cm_train, index=label_map, columns=label_map)\n",
    "df_cm_test = pd.DataFrame(cm_test, index=label_map, columns=label_map)\n",
    "\n",
    "# Function to create interactive Confusion Matrix\n",
    "def create_confusion_matrix_figure(conf_matrix, title):\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=conf_matrix.values,\n",
    "        x=conf_matrix.columns.tolist(),\n",
    "        y=conf_matrix.index.tolist(),\n",
    "        colorscale=\"Blues\",\n",
    "        showscale=True,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Predicted Label\",\n",
    "        yaxis_title=\"True Label\",\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# Create interactive plots for both train and test sets\n",
    "fig_train = create_confusion_matrix_figure(df_cm_train, \"Confusion Matrix - Train Set\")\n",
    "fig_test = create_confusion_matrix_figure(df_cm_test, \"Confusion Matrix - Test Set\")\n",
    "\n",
    "# Define file paths\n",
    "train_cm_path = os.path.join(output_dir, \"confusion_matrix_train.png\")\n",
    "test_cm_path = os.path.join(output_dir, \"confusion_matrix_test.png\")\n",
    "\n",
    "# Save Figures as Static PNGs\n",
    "fig_train.write_image(train_cm_path, scale=2)\n",
    "fig_test.write_image(test_cm_path, scale=2)\n",
    "\n",
    "# Show interactive Confusion Matrices in Jupyter Notebook\n",
    "fig_train.show()\n",
    "fig_test.show()\n",
    "\n",
    "# Display the saved static Confusion Matrices using Matplotlib (for GitHub visibility)\n",
    "for path, title in zip([train_cm_path, test_cm_path], [\"Train Set\", \"Test Set\"]):\n",
    "    img = plt.imread(path)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Confusion Matrix - {title}\")\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Confusion Matrices saved at: {train_cm_path} & {test_cm_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix - Insights\n",
    "\n",
    "- The **train set confusion matrix** shows a well-balanced classification, with very few misclassifications.  \n",
    "- The **test set confusion matrix** confirms strong generalization, as misclassification counts remain low, indicating that the model is not overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Generate classification reports as dictionaries\n",
    "report_train = classification_report(\n",
    "    y_true_train, y_pred_train, target_names=label_map, output_dict=True\n",
    ")\n",
    "report_test = classification_report(\n",
    "    y_true_test, y_pred_test, target_names=label_map, output_dict=True\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_train = pd.DataFrame(report_train).transpose().round(3)\n",
    "df_test = pd.DataFrame(report_test).transpose().round(3)\n",
    "\n",
    "# Print Train Report\n",
    "print(\"\\n### Classification Report - Train Set ###\\n\")\n",
    "print(df_train)\n",
    "\n",
    "# Print Test Report\n",
    "print(\"\\n### Classification Report - Test Set ###\\n\")\n",
    "print(df_test)\n",
    "\n",
    "# Save reports as CSV for future reference\n",
    "df_train.to_csv(f\"{output_dir}/classification_report_train.csv\")\n",
    "df_test.to_csv(f\"{output_dir}/classification_report_test.csv\")\n",
    "\n",
    "print(\n",
    "    f\"\\nReports saved to {output_dir}/classification_report_train.csv & {output_dir}/classification_report_test.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report - Insights\n",
    "\n",
    "- The **train set classification report** shows a balanced precision, recall, and F1-score, indicating that the model effectively learns from training data.  \n",
    "- The **test set classification report** confirms strong generalization, with nearly identical metrics across both classes, ensuring reliable performance on unseen data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate predictions (probabilities)\n",
    "y_probs_train = model_softmax.predict(train_set)\n",
    "y_probs_test = model_softmax.predict(test_set)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr_train, tpr_train, _ = roc_curve(\n",
    "    y_true_train, y_probs_train[:, 1]\n",
    ")  # Use class 1 probability\n",
    "fpr_test, tpr_test, _ = roc_curve(\n",
    "    y_true_test, y_probs_test[:, 1]\n",
    ")  # Use class 1 probability\n",
    "\n",
    "auc_train = auc(fpr_train, tpr_train)\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Create static ROC curve using Matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot Train ROC\n",
    "plt.plot(fpr_train, tpr_train, label=f\"Train AUC = {auc_train:.2f}\", color=\"blue\")\n",
    "\n",
    "# Plot Test ROC\n",
    "plt.plot(fpr_test, tpr_test, label=f\"Test AUC = {auc_test:.2f}\", color=\"green\")\n",
    "\n",
    "# Plot Random Guess Line (Baseline)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"dashed\", color=\"black\", label=\"Random (AUC = 0.50)\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.title(\"ROC Curve - Train vs Test\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Define file path\n",
    "roc_curve_path = os.path.join(output_dir, \"roc_curve.png\")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "plt.savefig(roc_curve_path, dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "# Show the static ROC curve in the notebook\n",
    "plt.show()\n",
    "\n",
    "print(f\"ROC Curve saved at: {roc_curve_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve - Insights\n",
    "\n",
    "- The **train ROC curve** demonstrates a high True Positive Rate (TPR) with minimal False Positive Rate (FPR), indicating strong discrimination ability.  \n",
    "- The **test ROC curve** closely follows the train curve, confirming that the model maintains high performance on unseen data without signs of overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance & Overfitting Analysis\n",
    "\n",
    "- The model achieved **99.64% accuracy** with a **low loss of 0.1486**, demonstrating strong performance.  \n",
    "- The **learning curves** confirm smooth convergence with no signs of major overfitting.  \n",
    "- The **confusion matrix and classification report** highlight minimal misclassification and high precision/recall.  \n",
    "- The **ROC curve** supports excellent class separation, ensuring the model generalizes well.  \n",
    "- Given these results, the model is **ready for deployment** with reliable predictive power.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Goal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results\n",
    "evaluation_results = joblib.load(\"outputs/v1/evaluation.pkl\")\n",
    "\n",
    "# Extract final test accuracy\n",
    "test_accuracy = evaluation_results[1]  \n",
    "\n",
    "# Check requirement\n",
    "accuracy_threshold = 0.90\n",
    "if test_accuracy >= accuracy_threshold:\n",
    "    print(f\"Model meets the business requirement! (Accuracy: {test_accuracy:.2%})\")\n",
    "else:\n",
    "    print(f\"Model does NOT meet the requirement. (Accuracy: {test_accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load random image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 66\n",
    "label = labels[0] \n",
    "pil_image = image.load_img(test_path + '/'+ label + '/'+ os.listdir(test_path+'/' + label)[pointer],\n",
    "                            target_size= image_shape, color_mode='rgb')\n",
    "\n",
    "print(f\" Image shape: {pil_image.size}, Image mode: {pil_image.mode}\")\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Image to Array and Prepare for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0) / 255.0  \n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0, 0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class = target_map[pred_proba < 0.5]\n",
    "\n",
    "if pred_class == target_map[1]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Record training duration\n",
    "end_time = time.time()\n",
    "training_time = round(end_time - start_time, 2)\n",
    "\n",
    "# Extract accuracy metrics from training history\n",
    "train_accuracy = round(history_softmax.history[\"accuracy\"][-1], 4)\n",
    "val_accuracy = round(history_softmax.history[\"val_accuracy\"][-1], 4)\n",
    "\n",
    "# Directly get test accuracy \n",
    "test_accuracy = round(test_accuracy, 4) if isinstance(test_accuracy, (int, float)) else None\n",
    "\n",
    "# Measure inference time\n",
    "start_inf_time = time.time()\n",
    "model.predict(my_image)  # Run prediction on a sample image\n",
    "end_inf_time = time.time()\n",
    "\n",
    "# Calculate inference time per image\n",
    "inference_time = round((end_inf_time - start_inf_time), 4)\n",
    "\n",
    "# Determine overfitting risk\n",
    "overfitting_risk = \"Yes\" if train_accuracy - val_accuracy > 0.05 else \"No\"\n",
    "\n",
    "# Store results in a structured format\n",
    "results = {\n",
    "    \"Model\": \"Softmax\",\n",
    "    \"Training Accuracy\": train_accuracy,\n",
    "    \"Validation Accuracy\": val_accuracy,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Training Time (sec)\": training_time,\n",
    "    \"Inference Time (sec/sample)\": inference_time,\n",
    "    \"Batch Size\": 16,\n",
    "    \"Overfitting Risk\": overfitting_risk,\n",
    "}\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "df_results = pd.DataFrame([results])\n",
    "\n",
    "# Save results to CSV (append mode)\n",
    "csv_file = \"training_results.csv\"\n",
    "df_results.to_csv(csv_file, mode=\"a\", index=False, header=not pd.io.common.file_exists(csv_file))\n",
    "\n",
    "# Display results as a table\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We successfully developed a deep learning model for image classification using a structured, beginner-friendly approach.  \n",
    "\n",
    "### **Key Achievements**\n",
    "- **Explored Multiple Architectures** → Compared Sigmoid, Softmax, and MobileNetV2 across different trials.  \n",
    "- **Comprehensive Evaluation** → Assessed models using accuracy, loss, confusion matrices, and ROC curves.  \n",
    "- **Optimized for Generalization** → Selected the best-performing model with minimal overfitting.  \n",
    "- **Deployment-Ready Model** → Finalized MobileNetV2 for real-world application.  \n",
    "\n",
    "### **Next Steps: Model Deployment**\n",
    "- **Web App Integration** → Implement a user-friendly Streamlit interface for real-time image classification.  \n",
    "- **Model Deployment** → Load the trained model and deploy it on a cloud platform for accessibility.  \n",
    "\n",
    "This deployment will enable efficient real-world usage, making automated classification accessible to users.  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
