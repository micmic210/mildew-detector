{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Modeling and Evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Dataset\n",
    "- inputs/mildew_dataset/cherry-leaves/train\n",
    "- inputs/mildew_dataset/cherry-leaves/validation\n",
    "- inputs/mildew_dataset/cherry-leaves/test\n",
    "\n",
    "Precomputed Features (from Data Visualization Notebook)\n",
    "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
    "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
    "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "### Data Processing & Visualization\n",
    "- **Dataset Distribution Plot** → Confirms balanced data split across training, validation, and test sets.  \n",
    "- **Data Augmentation Visualization** → Showcases applied transformations (rotation, flipping, zooming).  \n",
    "\n",
    "### Model Training & Evaluation\n",
    "- **Baseline CNN Models (Sigmoid & Softmax)** → Initial experiments to establish a benchmark.  \n",
    "- **MobileNetV2 Fine-Tuning** → Explored optimized architectures with different hyperparameters.  \n",
    "- **Best Model Selection** → Chose the most balanced model based on test accuracy, generalization, and robustness.  \n",
    "- **Saved Trained Model** → Final MobileNetV2 model stored for deployment.  \n",
    "\n",
    "### Model Performance & Explainability\n",
    "- **Learning Curves** → Visualizes loss and accuracy trends over epochs.  \n",
    "- **Histograms** → Displays predicted probability distributions.  \n",
    "- **Overfitting & Generalization Check** → Assesses potential overfitting using accuracy and loss gaps.  \n",
    "- **Confusion Matrices** → Shows classification performance for train, validation, and test sets.  \n",
    "- **Classification Reports** → Provides precision, recall, and F1-score analysis.  \n",
    "- **ROC Curves** → Evaluates model performance using Receiver Operating Characteristic analysis.  \n",
    "- **Business Goal Validation** → Confirms if the model meets the required accuracy threshold.  \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "- **Business Impact:** Enables early detection of powdery mildew, reducing manual inspection and improving monitoring.  \n",
    "- **Data-Driven Improvements:** Model refinements were based on data insights, ensuring balanced class distribution.  \n",
    "- **Deployment:** The optimized model is ready for Streamlit integration for real-world use.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/mildew-detector')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "#### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "## Set Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directories\n",
    "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
    "train_path = os.path.join(my_data_dir, 'train')\n",
    "val_path = os.path.join(my_data_dir, 'validation')\n",
    "test_path = os.path.join(my_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels for the images\n",
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images in Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dictionary\n",
    "data = {\n",
    "    'Set': [],\n",
    "    'Label': [],\n",
    "    'Frequency': []\n",
    "}\n",
    "\n",
    "# Define dataset folders\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each dataset split and count images\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        path = os.path.join(my_data_dir, folder, label)\n",
    "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "        print(f\" {folder}/{label}: {num_images} images\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_freq = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart - Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.title(\"Image Distribution in Dataset\")\n",
    "plt.xlabel(\"Dataset Split\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow/Keras ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize ImageDataGenerator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation for Training Set\n",
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Training Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Validation Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Augmented Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Augmented Images in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images_grid(data_generator, num_images=10):\n",
    "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
    "    img_batch, label_batch = next(data_generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
    "        ax.imshow(img_batch[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image grid\n",
    "plot_augmented_images_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2 was chosen for its efficiency, speed, and strong feature extraction while maintaining high accuracy with fewer parameters. Its lightweight architecture makes it ideal for deployment in resource-constrained environments. Details are provided in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best hyperparameters from tuning\n",
    "l2_lambda = 0.002  # Best L2 regularization strength\n",
    "best_units = 128  # Best number of dense units\n",
    "best_dropout = 0.4  # Best dropout rate\n",
    "best_lr = 0.0001  # Best learning rate\n",
    "\n",
    "# Create model\n",
    "model_mobilenet = Sequential(\n",
    "    [\n",
    "        MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3)),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(best_units, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(best_dropout),\n",
    "        Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_mobilenet.compile(\n",
    "    optimizer=Adam(learning_rate=best_lr),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "model_mobilenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Set EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce Learning Rate when `val_loss` stagnates\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "m_checkpoint = ModelCheckpoint(\n",
    "    filepath=\"outputs/v1/mobilenetv2.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model_mobilenet.fit(\n",
    "    train_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stop, lr_scheduler, m_checkpoint],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Training History\n",
    "df_history_mobilenet = pd.read_csv(\"outputs/v1/history_mobilenet.csv\")\n",
    "print(\"Training history loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained model\n",
    "model_mobilenet = load_model(\"outputs/v1/mobilenetv2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"outputs/v1/mobilenetv2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set, batch_size=batch_size)\n",
    "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
    "print(\"Model Loss: \", evaluation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Accuracy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly obtain true labels\n",
    "y_true = test_set.labels\n",
    "\n",
    "# Obtain model predictions\n",
    "preds = model.predict(test_set)\n",
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Convert df_history_mobilenet to long format for Plotly\n",
    "df_long = df_history_mobilenet.reset_index().melt(\n",
    "    id_vars=[\"index\"],\n",
    "    value_vars=[\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"],\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Value\",\n",
    ")\n",
    "df_long.rename(columns={\"index\": \"Epoch\"}, inplace=True)\n",
    "\n",
    "# Split into two DataFrames: one for loss, one for accuracy\n",
    "df_loss = df_long[df_long[\"Metric\"].isin([\"loss\", \"val_loss\"])]\n",
    "df_acc = df_long[df_long[\"Metric\"].isin([\"accuracy\", \"val_accuracy\"])]\n",
    "\n",
    "# Interactive Loss Curve\n",
    "fig_loss = px.line(\n",
    "    df_loss,\n",
    "    x=\"Epoch\",\n",
    "    y=\"Value\",\n",
    "    color=\"Metric\",\n",
    "    markers=True,\n",
    "    title=\"Loss - MobileNetV2\",\n",
    "    labels={\"Value\": \"Loss\", \"Epoch\": \"Epoch\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Interactive Accuracy Curve\n",
    "fig_acc = px.line(\n",
    "    df_acc,\n",
    "    x=\"Epoch\",\n",
    "    y=\"Value\",\n",
    "    color=\"Metric\",\n",
    "    markers=True,\n",
    "    title=\"Accuracy - MobileNetV2\",\n",
    "    labels={\"Value\": \"Accuracy\", \"Epoch\": \"Epoch\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Save the figures as static PNGs\n",
    "fig_loss.write_image(f\"{output_dir}/model_training_losses.png\", scale=2)\n",
    "fig_acc.write_image(f\"{output_dir}/model_training_acc.png\", scale=2)\n",
    "\n",
    "# Show interactive plots\n",
    "fig_loss.show()\n",
    "fig_acc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy:** Training accuracy quickly reaches **~1.0**, while validation accuracy steadily improves with a small gap (~1%).  \n",
    "- **Loss:** Both training and validation loss decrease consistently, showing stable learning with **no major overfitting**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram below shows the overall distribution of model confidence scores for predictions on the test set. To explore individual image confidence levels and analyze misclassifications, please refer to the interactive version in the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_probs = model_mobilenet.predict(validation_set)\n",
    "\n",
    "# Create DataFrame for Plotly\n",
    "df_probs = pd.DataFrame({\"Healthy\": y_pred_probs[:, 0], \"Infected\": y_pred_probs[:, 1]})\n",
    "\n",
    "# Create histogram traces for both classes\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_probs[\"Healthy\"],\n",
    "        nbinsx=20,\n",
    "        opacity=0.6,\n",
    "        name=\"Healthy\",\n",
    "        marker_color=\"green\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_probs[\"Infected\"],\n",
    "        nbinsx=20,\n",
    "        opacity=0.6,\n",
    "        name=\"Infected\",\n",
    "        marker_color=\"blue\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add threshold line at 0.5\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5, 0.5],\n",
    "        y=[\n",
    "            0,\n",
    "            max(np.histogram(y_pred_probs[:, 1], bins=20)[0]),\n",
    "        ],  # Adjust y-axis dynamically\n",
    "        mode=\"lines\",\n",
    "        name=\"Threshold = 0.5\",\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Prediction Probability Histogram\",\n",
    "    xaxis_title=\"Prediction Probability\",\n",
    "    yaxis_title=\"Count\",\n",
    "    barmode=\"overlay\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "fig.write_image(f\"{output_dir}/histogram_test.png\", scale=2)\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows a clear separation between **healthy** and **infected** predictions, with most probabilities concentrated near 0 and 1. The decision threshold at **0.5** is well-placed, ensuring confident classifications. Minimal overlap suggests strong model confidence in distinguishing between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting & Generalization Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last recorded training & validation metrics\n",
    "train_acc = history_mobilenet.history[\"accuracy\"][-1]\n",
    "val_acc = history_mobilenet.history[\"val_accuracy\"][-1]\n",
    "train_loss = history_mobilenet.history[\"loss\"][-1]\n",
    "val_loss = history_mobilenet.history[\"val_loss\"][-1]\n",
    "\n",
    "# Compute Generalization Gap\n",
    "accuracy_gap = train_acc - val_acc\n",
    "loss_gap = val_loss - train_loss\n",
    "\n",
    "print(\"\\n### Generalization & Overfitting Check ###\")\n",
    "print(f\"Final Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Accuracy Gap: {accuracy_gap:.4f}\")\n",
    "\n",
    "print(f\"Final Train Loss: {train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Loss Gap: {loss_gap:.4f}\")\n",
    "\n",
    "# Overfitting Analysis\n",
    "if accuracy_gap > 0.05:\n",
    "    print(\n",
    "        \"\\nOverfitting detected: The model performs significantly better on training data than validation data.\"\n",
    "    )\n",
    "\n",
    "if loss_gap > 0.05:\n",
    "    print(\n",
    "        \"\\nOverfitting detected: Validation loss is significantly higher than training loss.\"\n",
    "    )\n",
    "\n",
    "if accuracy_gap < 0.05 and loss_gap < 0.05:\n",
    "    print(\"\\nNo significant overfitting detected. Model generalizes well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Get Class Labels\n",
    "label_map = list(test_set.class_indices.keys())\n",
    "\n",
    "# Evaluate Model on Train and Test Sets\n",
    "y_true_train = train_set.classes\n",
    "y_pred_train = np.argmax(model_mobilenet.predict(train_set), axis=1)\n",
    "\n",
    "y_true_test = test_set.classes\n",
    "y_pred_test = np.argmax(model_mobilenet.predict(test_set), axis=1)\n",
    "\n",
    "# Generate Confusion Matrices\n",
    "cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "\n",
    "# Convert confusion matrices to DataFrames\n",
    "df_cm_train = pd.DataFrame(cm_train, index=label_map, columns=label_map)\n",
    "df_cm_test = pd.DataFrame(cm_test, index=label_map, columns=label_map)\n",
    "\n",
    "\n",
    "# Function to create interactive Confusion Matrix\n",
    "def create_confusion_matrix_figure(conf_matrix, title):\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=conf_matrix.values,\n",
    "        x=conf_matrix.columns.tolist(),\n",
    "        y=conf_matrix.index.tolist(),\n",
    "        colorscale=\"Blues\",\n",
    "        showscale=True,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Predicted Label\",\n",
    "        yaxis_title=\"True Label\",\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create interactive plots separately\n",
    "fig_train = create_confusion_matrix_figure(df_cm_train, \"Confusion Matrix - Train Set\")\n",
    "fig_test = create_confusion_matrix_figure(df_cm_test, \"Confusion Matrix - Test Set\")\n",
    "\n",
    "# Save Figures as Static PNGs\n",
    "fig_train.write_image(os.path.join(output_dir, \"confusion_matrix_train.png\"), scale=2)\n",
    "fig_test.write_image(os.path.join(output_dir, \"confusion_matrix_test.png\"), scale=2)\n",
    "\n",
    "# Show interactive plots one after another (not side by side)\n",
    "fig_train.show()\n",
    "fig_test.show()\n",
    "\n",
    "print(\n",
    "    f\"Confusion Matrices saved at: {output_dir}/confusion_matrix_train.png & {output_dir}/confusion_matrix_test.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well on both the training and test sets, with a high number of correct classifications. The test set shows **zero false positives**, meaning no healthy samples were misclassified as infected. A small number of false negatives (7 cases) suggest slight room for improvement in detecting infections, but overall accuracy remains strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Generate classification reports as text\n",
    "report_train = classification_report(\n",
    "    y_true_train, y_pred_train, target_names=label_map, digits=3\n",
    ")\n",
    "report_test = classification_report(\n",
    "    y_true_test, y_pred_test, target_names=label_map, digits=3\n",
    ")\n",
    "\n",
    "# Print Train Report\n",
    "print(\"\\n### Classification Report - Train Set ###\\n\")\n",
    "print(report_train)\n",
    "\n",
    "# Print Test Report\n",
    "print(\"\\n### Classification Report - Test Set ###\\n\")\n",
    "print(report_test)\n",
    "\n",
    "# Save reports as text files\n",
    "with open(f\"{output_dir}/classification_report_train.txt\", \"w\") as f:\n",
    "    f.write(report_train)\n",
    "\n",
    "with open(f\"{output_dir}/classification_report_test.txt\", \"w\") as f:\n",
    "    f.write(report_test)\n",
    "\n",
    "print(\"\\nReports saved to outputs/v1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report shows a clear improvement from training to testing. While the training set had balanced but poor performance (around 49.6% accuracy), the test set achieved 99.2% accuracy, with high precision and recall for both classes. This suggests that the model trained effectively despite initial challenges, generalizing well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Generate predictions (probabilities)\n",
    "y_probs_train = model_mobilenet.predict(train_set)\n",
    "y_probs_test = model_mobilenet.predict(test_set)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_true_train, y_probs_train[:, 1])\n",
    "fpr_test, tpr_test, _ = roc_curve(y_true_test, y_probs_test[:, 1])\n",
    "\n",
    "auc_train = auc(fpr_train, tpr_train)\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Create an interactive Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Train ROC Curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr_train,\n",
    "        y=tpr_train,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Train AUC = {auc_train:.2f}\",\n",
    "        line=dict(color=\"blue\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add Test ROC Curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr_test,\n",
    "        y=tpr_test,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Test AUC = {auc_test:.2f}\",\n",
    "        line=dict(color=\"green\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add Random Guess Line (Baseline)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Random (AUC = 0.50)\",\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"ROC Curve - Train vs Test\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.7, y=0.2),\n",
    ")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "roc_curve_path = os.path.join(output_dir, \"roc_curve.png\")\n",
    "fig.write_image(roc_curve_path, scale=2)\n",
    "\n",
    "# Show interactive plot\n",
    "fig.show()\n",
    "\n",
    "print(f\"ROC Curve saved at: {roc_curve_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test ROC curve shows **perfect AUC (1.00)**, indicating strong model performance with **no false positives**. However, the train AUC is low (**0.49**), suggesting a potential issue in training evaluation. Further investigation may be needed to confirm the validity of the training metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(evaluation, filename=f\"{output_dir}/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Goal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define minimum required accuracy\n",
    "accuracy_threshold = 0.90\n",
    "\n",
    "# Load evaluation results\n",
    "evaluation_results = joblib.load(\"outputs/draft_mobilenetv2/evaluation.pkl\")\n",
    "\n",
    "# Extract final test accuracy\n",
    "test_accuracy = evaluation_results[\"test_accuracy\"]\n",
    "\n",
    "# Check requirement\n",
    "if test_accuracy >= accuracy_threshold:\n",
    "    print(f\"Model meets the business requirement! (Accuracy: {test_accuracy:.2%})\")\n",
    "else:\n",
    "    print(f\"Model does NOT meet the requirement. (Accuracy: {test_accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load a test image from dataset\n",
    "sample_index = 7  # Adjust if needed\n",
    "X_test_batch, y_test_batch = next(iter(test_set))  # Extract a batch\n",
    "sample_image = X_test_batch[sample_index]  # Select one test image\n",
    "sample_label = int(y_test_batch[sample_index])  # Convert label to integer\n",
    "\n",
    "# Convert image to TensorFlow tensor (for gradient computation)\n",
    "img_tensor = tf.convert_to_tensor(\n",
    "    sample_image[None], dtype=tf.float32\n",
    ")  # Add batch dimension\n",
    "\n",
    "# Load your tuned model\n",
    "model = model_mobilenet  # Assuming MobileNetV2 is already loaded\n",
    "\n",
    "# Compute gradients of the class score w.r.t. the input image\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(img_tensor)  # Track changes to the image\n",
    "    preds = model(img_tensor)  # Get model predictions\n",
    "    loss = preds[:, sample_label]  # Focus on the predicted class\n",
    "\n",
    "# Compute gradients w.r.t. the input image\n",
    "grads = tape.gradient(loss, img_tensor)[0]\n",
    "\n",
    "# Convert gradients to absolute values and take the max across color channels\n",
    "saliency_map = np.max(np.abs(grads), axis=-1).numpy()\n",
    "\n",
    "# Normalize saliency map (to range 0-1)\n",
    "saliency_map = (saliency_map - np.min(saliency_map)) / (\n",
    "    np.max(saliency_map) - np.min(saliency_map) + 1e-8\n",
    ")\n",
    "\n",
    "# Apply Exponential Scaling to Enhance Weak Signals\n",
    "saliency_map = np.power(saliency_map, 3)  # Amplify small differences\n",
    "\n",
    "# Convert to 8-bit (0-255) for better visualization\n",
    "saliency_map = (saliency_map * 255).astype(np.uint8)\n",
    "\n",
    "# Apply Histogram Equalization to Improve Contrast\n",
    "saliency_map = cv2.equalizeHist(saliency_map)\n",
    "\n",
    "# Apply a Stronger Colormap for More Visible Heatmap\n",
    "saliency_colored = cv2.applyColorMap(\n",
    "    saliency_map, cv2.COLORMAP_HOT\n",
    ")  # Use 'HOT' colormap for high contrast\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Show Original Image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(\n",
    "    np.clip(sample_image * 255, 0, 255).astype(\"uint8\")\n",
    ")  # Rescale for better visibility\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original Image (Enhanced Contrast)\")\n",
    "\n",
    "# Show Strongly Enhanced Saliency Map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(\n",
    "    cv2.cvtColor(saliency_colored, cv2.COLOR_BGR2RGB)\n",
    ")  # Convert OpenCV BGR to RGB\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Strongly Enhanced Saliency Map\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Select the last convolutional layer\n",
    "gradcam_layer = \"block_16_project\"  # Confirm this from model_mobilenet.layers[0].layers\n",
    "\n",
    "# Load an image and preprocess it\n",
    "img_path = \"path_to_your_image.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (128, 128))  # Match MobileNetV2 input size\n",
    "img = np.expand_dims(img, axis=0) / 255.0  # Normalize and add batch dimension\n",
    "\n",
    "# Load MobileNetV2 model (your modified version)\n",
    "model = model_mobilenet\n",
    "\n",
    "# Get the model's last convolutional layer and predictions\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.input],\n",
    "    [\n",
    "        model.get_layer(\"mobilenetv2_1.00_128\").get_layer(gradcam_layer).output,\n",
    "        model.output,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Compute the gradient of the class score w.r.t. the last convolutional layer\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_output, preds = grad_model(img)\n",
    "    class_idx = np.argmax(preds)  # Target class (most confident prediction)\n",
    "    loss = preds[:, class_idx]  # Get the score of the predicted class\n",
    "\n",
    "# Compute gradients\n",
    "grads = tape.gradient(loss, conv_output)\n",
    "\n",
    "# Global average pooling of gradients\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# Multiply weights by activations\n",
    "heatmap = conv_output[0] @ pooled_grads[..., tf.newaxis]\n",
    "heatmap = tf.squeeze(heatmap).numpy()\n",
    "\n",
    "# Normalize the heatmap\n",
    "heatmap = np.maximum(heatmap, 0)  # ReLU activation\n",
    "heatmap /= np.max(heatmap)  # Normalize between 0-1\n",
    "\n",
    "# Load original image (without batch dimension)\n",
    "original_img = cv2.imread(img_path)\n",
    "original_img = cv2.resize(original_img, (128, 128))\n",
    "\n",
    "# Resize heatmap to match original image\n",
    "heatmap = cv2.resize(heatmap, (128, 128))\n",
    "\n",
    "# Convert heatmap to color\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "# Overlay heatmap on original image\n",
    "overlay = cv2.addWeighted(original_img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap, cmap=\"jet\")\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Overlayed Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the saved MobileNetV2 model\n",
    "model_mobilenet = load_model(\"outputs/draft_mobilenetv2/mildew_detector_mobilenetv2.h5\", compile=False)\n",
    "\n",
    "# Explicitly recompile to restore metrics\n",
    "model_mobilenet.compile(\n",
    "    optimizer=Adam(learning_rate=0.00005),  \n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Load a Random Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test image selection parameters\n",
    "pointer = 60  # Change this number to select a different image\n",
    "label = labels[1]  # Select \"Healthy\" (0) or \"Infected\" (1)\n",
    "\n",
    "# Load the image using PIL\n",
    "img_path = test_path + \"/\" + label + \"/\" + os.listdir(test_path + \"/\" + label)[pointer]\n",
    "pil_image = image.load_img(img_path, target_size=image_shape, color_mode=\"rgb\")\n",
    "\n",
    "# Display image details\n",
    "print(f\"Selected Image Path: {img_path}\")\n",
    "print(f\"Image shape: {pil_image.size}, Image mode: {pil_image.mode}\")\n",
    "\n",
    "# Show the image\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Image to Array and Prepare for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0) / 255.0  # Normalize pixel values\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction & Display Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "pred_proba = model.predict(my_image)[0, 0]  # Extract single probability score\n",
    "\n",
    "# Map indices to class labels\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}  # Reverse mapping\n",
    "pred_class = target_map[int(pred_proba > 0.5)]  # Ensure correct label mapping\n",
    "\n",
    "# Adjust probability if necessary\n",
    "if pred_class == target_map[0]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "# Print prediction results\n",
    "print(f\"Predicted Class: {pred_class}\")\n",
    "print(f\"Prediction Probability: {pred_proba:.4f}\")\n",
    "\n",
    "# Save the image to outputs/draft for PDF report\n",
    "os.makedirs(\"outputs/draft_mobilenetv2\", exist_ok=True)\n",
    "pil_image.save(\"outputs/draft_mobilenetv2/selected_test_image.png\")\n",
    "\n",
    "# Save prediction results as a text file\n",
    "with open(\"outputs/draft_mobilenetv2/prediction_result.txt\", \"w\") as f:\n",
    "    f.write(f\"Predicted Class: {pred_class}\\n\")\n",
    "    f.write(f\"Prediction Probability: {pred_proba:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We successfully developed a deep learning model for image classification using a structured, beginner-friendly approach.  \n",
    "\n",
    "### **Key Achievements**\n",
    "- **Explored Multiple Architectures** → Compared Sigmoid, Softmax, and MobileNetV2 across different trials.  \n",
    "- **Comprehensive Evaluation** → Assessed models using accuracy, loss, confusion matrices, and ROC curves.  \n",
    "- **Optimized for Generalization** → Selected the best-performing model with minimal overfitting.  \n",
    "- **Deployment-Ready Model** → Finalized MobileNetV2 for real-world application.  \n",
    "\n",
    "### **Next Steps: Model Deployment**\n",
    "- **Web App Integration** → Implement a user-friendly Streamlit interface for real-time image classification.  \n",
    "- **Model Deployment** → Load the trained model and deploy it on a cloud platform for accessibility.  \n",
    "\n",
    "This deployment will enable efficient real-world usage, making automated classification accessible to users.  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
