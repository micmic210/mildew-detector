{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modeling and Evaluation Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
        "- Build and evaluate models: Implement a baseline CNN model, refine it through hyperparameter tuning, and assess performance.\n",
        "- Analyze model effectiveness: Use Saliency Maps and t-SNE visualization to interpret model predictions and feature separability.\n",
        "- Compare model performance: Select the best model based on accuracy, loss, and efficiency for real-world deployment.\n",
        "- Prepare for deployment: Save the optimized model for integration into a Streamlit web app hosted on Heroku.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "Dataset\n",
        "- inputs/mildew_dataset/cherry-leaves/train\n",
        "- inputs/mildew_dataset/cherry-leaves/validation\n",
        "- inputs/mildew_dataset/cherry-leaves/test\n",
        "\n",
        "Precomputed Features (from Data Visualization Notebook)\n",
        "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
        "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
        "- Feature Space Visualization → PCA confirms class separability.\n",
        "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "Data Processing & Visualization\n",
        "- Dataset Distribution Plot → Confirmed balanced data split across training, validation, and test sets.\n",
        "- Data Augmentation Visualization → Showcased applied transformations, including rotation, flipping, and zooming.\n",
        "Model Training & Optimization\n",
        "- Baseline CNN Model → Implemented a standard CNN to establish initial performance.\n",
        "- Hyperparameter-Tuned CNN → Optimized model performance using Keras Tuner (adjusting filters, dropout, learning rate, and L2 regularization).\n",
        "- Best Model Selection → Chose the Tuned CNN based on test accuracy and generalization ability.\n",
        "- Saved Trained Models → Final model stored for Streamlit integration and deployment on Heroku.\n",
        "Model Evaluation & Explainability\n",
        "- Learning Curves → Visualized loss and accuracy trends over epochs.\n",
        "- Confusion Matrices → Displayed classification performance for train, validation, and test sets.\n",
        "- Classification Reports → Provided precision, recall, and F1-score analysis.\n",
        "- Saliency Maps → Highlighted regions in images that influenced the model’s predictions.\n",
        "- Feature Space Visualization (t-SNE) → Compared Baseline CNN and Tuned CNN feature separability.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- Business Impact: The trained model can assist in early detection of powdery mildew, reducing manual inspection time and improving plantation monitoring efficiency.\n",
        "- Data-Driven Enhancements: Model improvements were guided by data preprocessing insights, including PCA feature visualization and class balance validation.\n",
        "- Deployment Readiness: The best model was optimized and prepared for integration into a Streamlit web app for real-world application.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Set Data Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cwd= os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir('/workspaces/mildew-detector')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "#### Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Set Input Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set input directories\n",
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = os.path.join(my_data_dir, 'train')\n",
        "val_path = os.path.join(my_data_dir, 'validation')\n",
        "test_path = os.path.join(my_data_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the labels for the images\n",
        "labels = os.listdir(train_path)\n",
        "print('Label for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of Images in Train, Test and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define dataset path\n",
        "my_data_dir = \"inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "# Define dataset splits and labels\n",
        "sets = ['train', 'test', 'validation']\n",
        "labels = ['Healthy', 'Infected']\n",
        "\n",
        "# Create a dictionary for structured storage\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "total_images = 0  # Initialize total count\n",
        "\n",
        "# Loop through each dataset split and count images\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = os.path.join(my_data_dir, set_name, label)\n",
        "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
        "        \n",
        "        # Print count\n",
        "        print(f\"{set_name}/{label}: {num_images} images\")\n",
        "\n",
        "        # Store in dictionary\n",
        "        data['Set'].append(set_name)\n",
        "        data['Label'].append(label)\n",
        "        data['Frequency'].append(num_images)\n",
        "\n",
        "        # Update total count\n",
        "        total_images += num_images\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "# Print total images\n",
        "print(f\"\\nTotal number of images: {total_images}\")\n",
        "\n",
        "# Display DataFrame\n",
        "import ace_tools as tools\n",
        "tools.display_dataframe_to_user(name=\"Image Frequency Data\", dataframe=df_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bar Chart - Image Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.title(\"Image Distribution in Dataset\")\n",
        "plt.xlabel(\"Dataset Split\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implement Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import TensorFlow/Keras ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment Training, Validation, and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Initialize ImageDataGenerator for Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define Augmentation for Training Set\n",
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Augment Training Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 20  # Set batch size\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Augment Validation Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='binary',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Augment Test Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='binary',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of Augmented Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Augmented Training Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(train_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Augmented Validation and Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(validation_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(test_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Class Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Multiple Augmented Images in a Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_augmented_images_grid(data_generator, num_images=10):\n",
        "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
        "    img_batch, label_batch = next(data_generator)\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
        "        ax.imshow(img_batch[i])\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
        "    plt.show()\n",
        "\n",
        "# Display the augmented image grid\n",
        "plot_augmented_images_grid(train_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input  \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this project, a Convolutional Neural Network (CNN) was selected because it is highly effective for image classification tasks. Unlike traditional machine learning models, CNNs can automatically learn hierarchical spatial features from images, making them ideal for detecting powdery mildew in cherry leaves.\n",
        "\n",
        "### Why CNN Over Other Models?\n",
        "\n",
        "| **Model**                        | **Reason for Exclusion** |\n",
        "|----------------------------------|-----------------------------------------------------------|\n",
        "| **Logistic Regression**          | Inefficient for image data; lacks feature extraction capabilities. |\n",
        "| **Random Forest**                | Performs well on structured data but struggles with high-dimensional images. |\n",
        "| **Support Vector Machines (SVM)** | Computationally expensive for large image datasets; lacks spatial feature extraction. |\n",
        "| **Fully Connected Neural Networks (MLP)** | Requires excessive parameters and lacks spatial feature learning. |\n",
        "\n",
        "CNNs are specifically designed for image processing, as they utilize convolutional layers to detect local features like **leaf texture, shape, and mildew presence** while minimizing computational overhead. Unlike traditional machine learning models, CNNs leverage **spatial hierarchies** in images, enabling efficient feature extraction without requiring extensive manual preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Features of the Model\n",
        "- **Four convolutional layers** efficiently extract hierarchical patterns.\n",
        "- **Batch normalization** stabilizes training and accelerates convergence.\n",
        "- **L2 regularization (0.001)** prevents overfitting by constraining large weights.\n",
        "- **Dropout (0.3)** improves generalization by reducing reliance on specific neurons.\n",
        "- **Adam optimizer (0.0001 LR)** balances training speed and stability.\n",
        "- **Sigmoid activation** ensures a probability-based classification of \"Healthy\" or \"Infected\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_base_cnn():\n",
        "    \"\"\"\n",
        "    Creates a Convolutional Neural Network (CNN) model for binary classification.\n",
        "\n",
        "    The model consists of:\n",
        "    - Convolutional layers with ReLU activation and L2 regularization\n",
        "    - MaxPooling layers for downsampling\n",
        "    - Fully connected Dense layers with Dropout for regularization\n",
        "    - Sigmoid activation for binary classification (Healthy vs. Infected)\n",
        "\n",
        "    Returns:\n",
        "        model: A compiled Keras CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential(\n",
        "        [\n",
        "            # Explicit Input Layer (Fixes the Warning)\n",
        "            Input(shape=image_shape),  \n",
        "\n",
        "            # First convolutional block\n",
        "            Conv2D(\n",
        "                filters=32,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(0.001),  \n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Second convolutional block\n",
        "            Conv2D(\n",
        "                filters=64,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(0.001),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Third convolutional block\n",
        "            Conv2D(\n",
        "                filters=128,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(0.001),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Fourth convolutional block\n",
        "            Conv2D(\n",
        "                filters=128,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(0.001),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Flatten the feature maps into a single vector\n",
        "            Flatten(),\n",
        "\n",
        "            # Fully connected layers\n",
        "            Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
        "            Dropout(0.3),  # Dropout layer to prevent overfitting\n",
        "\n",
        "            # Output layer for binary classification\n",
        "            Dense(1, activation=\"sigmoid\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate the CNN model\n",
        "model_cnn = create_base_cnn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Summary "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the base CNN model\n",
        "model_base_cnn = create_base_cnn()\n",
        "\n",
        "# Print model summary\n",
        "model_base_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early Stopping Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set EarlyStopping callback\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit CNN model for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the CNN model\n",
        "model_base_cnn = create_base_cnn()\n",
        "\n",
        "# Train the base CNN model\n",
        "history_base_cnn = model_base_cnn.fit(\n",
        "    train_set,\n",
        "    epochs=20,\n",
        "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "    validation_data=validation_set,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained base CNN model\n",
        "model_base_cnn.save('outputs/v1/mildew_detector_base_cnn.keras')\n",
        "print(\"Base CNN model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Performance & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Base CNN on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the base CNN model\n",
        "test_loss_base_cnn, test_accuracy_base_cnn = model_base_cnn.evaluate(test_set)\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Test Accuracy (Base CNN): {test_accuracy_base_cnn:.4f}\")\n",
        "print(f\"Test Loss (Base CNN): {test_loss_base_cnn:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Training History for Base CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert training history of Base CNN to DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "df_history_base_cnn = pd.DataFrame(history_base_cnn.history)\n",
        "\n",
        "# Save history for later use\n",
        "df_history_base_cnn.to_csv(\"outputs/v1/history_base_cnn.csv\", index=False)\n",
        "print(\"Base CNN training history saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Learning Curve (Loss & Accuracy) for Base CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot Loss Curve\n",
        "df_history_base_cnn[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{file_path}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy Curve\n",
        "df_history_base_cnn[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{file_path}/model_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remarks:\n",
        "\n",
        "The learning curve indicates a smooth decline in training and validation loss, showing that the model is learning effectively. However, the slight divergence at later epochs suggests potential overfitting. The accuracy curve stabilizes close to 100%, implying strong model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix & Classification Report (Train & Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_dir = \"outputs/v1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "def generate_confusion_matrix(y_true, y_pred, label_map, set_name):\n",
        "    \"\"\"\n",
        "    Generates, displays, and saves a static confusion matrix.\n",
        "    \n",
        "    Parameters:\n",
        "    - y_true: Actual class labels\n",
        "    - y_pred: Predicted class labels\n",
        "    - label_map: List of class names\n",
        "    - set_name: Dataset name (Train, Validation, Test)\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=label_map, columns=label_map)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5)\n",
        "    plt.title(f\"Confusion Matrix - {set_name} Set\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and show confusion matrix\n",
        "    save_path = os.path.join(output_dir, f\"confusion_matrix_{set_name.lower()}.png\")\n",
        "    plt.savefig(save_path, dpi=150)\n",
        "    plt.show()  # Display in the notebook\n",
        "    print(f\"Confusion Matrix saved at: {save_path}\")\n",
        "\n",
        "\n",
        "def generate_classification_report(y_true, y_pred, label_map, set_name):\n",
        "    \"\"\"\n",
        "    Generates, prints, and saves a classification report.\n",
        "    \n",
        "    Parameters:\n",
        "    - y_true: Actual class labels\n",
        "    - y_pred: Predicted class labels\n",
        "    - label_map: List of class names\n",
        "    - set_name: Dataset name (Train, Validation, Test)\n",
        "    \"\"\"\n",
        "    report = classification_report(y_true, y_pred, target_names=label_map)\n",
        "    \n",
        "    print(f\"\\n--- Classification Report: {set_name} Set ---\\n\")\n",
        "    print(report)\n",
        "\n",
        "    # Save report as a text file\n",
        "    report_path = os.path.join(output_dir, f\"classification_report_{set_name.lower()}.txt\")\n",
        "    with open(report_path, \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    print(f\"Classification report saved at: {report_path}\")\n",
        "\n",
        "\n",
        "def evaluate_model(generator, model, label_map, set_name, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluates model performance by generating a confusion matrix and classification report.\n",
        "    \n",
        "    Parameters:\n",
        "    - generator: Data generator (train, validation, or test)\n",
        "    - model: Trained model\n",
        "    - label_map: List of class names\n",
        "    - set_name: Dataset name (Train, Validation, Test)\n",
        "    - threshold: Probability threshold for classification (default: 0.5)\n",
        "    \"\"\"\n",
        "    y_true = generator.classes  # True labels\n",
        "    y_pred_probs = model.predict(generator)  # Model predictions (probabilities)\n",
        "    y_pred = (y_pred_probs > threshold).astype(int).flatten()  # Convert to class labels\n",
        "\n",
        "    print(f\"\\n#### {set_name} Set Evaluation ####\\n\")\n",
        "\n",
        "    # Generate and display confusion matrix\n",
        "    generate_confusion_matrix(y_true, y_pred, label_map, set_name)\n",
        "\n",
        "    # Generate and print classification report\n",
        "    generate_classification_report(y_true, y_pred, label_map, set_name)\n",
        "\n",
        "\n",
        "# Get class labels from training set\n",
        "label_map = list(train_set.class_indices.keys())\n",
        "\n",
        "# Evaluate the model on Train, Validation, and Test sets\n",
        "evaluate_model(train_set, model_base_cnn, label_map, \"Train\")\n",
        "evaluate_model(test_set, model_base_cnn, label_map, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remarks:**\n",
        "\n",
        "- Train Set: The model exhibits moderate misclassification between healthy and infected leaves, with precision and recall around 52%. This suggests the model struggles to distinguish between the two classes in the training set.\n",
        "\n",
        "- Test Set: The model performs significantly better, achieving near-perfect classification (precision, recall, and F1-score of 1.00). This indicates the model generalizes well, despite inconsistencies in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Saved Model (必要？？？)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('outputs/v1/mildew_detector_cnn.keras')\n",
        "print(\"\\nModel loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Evaluation Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store evaluation results with the correct variable names\n",
        "evaluation = {\n",
        "    \"test_loss\": test_loss_base_cnn, \n",
        "    \"test_accuracy\": test_accuracy_base_cnn\n",
        "}\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Save evaluation results\n",
        "joblib.dump(value=evaluation, filename=\"outputs/v1/evaluation_base_cnn.pkl\")\n",
        "print(\"\\nModel evaluation results saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detecting and Analyzing Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convert training history to DataFrame (Base CNN)\n",
        "df_history_base_cnn = pd.DataFrame(history_base_cnn.history)  # Ensure correct variable is used\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot Training & Validation Loss\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(df_history_base_cnn[\"loss\"], label=\"Training Loss\", marker=\"o\")\n",
        "plt.plot(df_history_base_cnn[\"val_loss\"], label=\"Validation Loss\", marker=\"o\")\n",
        "plt.title(\"Loss Curve (Base CNN)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Training & Validation Accuracy\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(df_history_base_cnn[\"accuracy\"], label=\"Training Accuracy\", marker=\"o\")\n",
        "plt.plot(df_history_base_cnn[\"val_accuracy\"], label=\"Validation Accuracy\", marker=\"o\")\n",
        "plt.title(\"Accuracy Curve (Base CNN)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Identify Overfitting\n",
        "train_acc = df_history_base_cnn[\"accuracy\"].iloc[-1]\n",
        "val_acc = df_history_base_cnn[\"val_accuracy\"].iloc[-1]\n",
        "train_loss = df_history_base_cnn[\"loss\"].iloc[-1]\n",
        "val_loss = df_history_base_cnn[\"val_loss\"].iloc[-1]\n",
        "\n",
        "print(\"\\n### Overfitting Analysis (Base CNN) ###\")\n",
        "print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Final Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Improved Overfitting Check\n",
        "if (train_acc - val_acc > 0.05) or (train_loss < val_loss - 0.05):\n",
        "    print(\"\\nWarning: Possible Overfitting Detected!\")\n",
        "else:\n",
        "    print(\"\\nNo significant overfitting detected. The model generalizes well.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remark: Overfitting Analysis (Base CNN)**\n",
        "\n",
        "The training and validation curves show consistent trends, indicating that the model generalizes well without significant overfitting.\n",
        "\n",
        "Key Observations:\n",
        "- Training vs. Validation Accuracy: Both curves closely follow each other, with final validation accuracy (0.9762) slightly higher than training accuracy (0.9500).\n",
        "- Training vs. Validation Loss: The loss values remain similar, suggesting that the model is not memorizing the training data but learning meaningful patterns.\n",
        "- No sharp divergence between training and validation metrics, reinforcing that overfitting is not a major concern.\n",
        "\n",
        "Conclusion: The base CNN demonstrates good generalization, making it a reliable baseline for further improvements. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter Tuning with Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimize the CNN model using Keras Tuner to improve performance while preventing overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,  \n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Hyperparameter Search Space\n",
        "The hyperparameter values were selected based on a balance between model performance, generalization ability, and computational efficiency. The choices aim to enhance feature extraction while preventing overfitting and maintaining training stability.\n",
        "\n",
        "| **Hyperparameter**       | **Values Tested**       | **Rationale** |\n",
        "|-------------------------|------------------------|--------------|\n",
        "| **Number of Filters** (num_filters_1 to num_filters_4) | [32, 64, 128, 256] | Increasing filter sizes in deeper layers helps extract hierarchical features while balancing computational cost. |\n",
        "| **L2 Regularization** (l2_reg) | [0.0001, 0.001, 0.0005] | Helps prevent overfitting by applying weight penalties, ensuring smooth generalization. |\n",
        "| **Dropout Rate** (dropout_rate) | [0.2, 0.3] | Reduces overfitting by randomly deactivating neurons during training. Moderate dropout rates retain learning capacity while preventing memorization. |\n",
        "| **Learning Rate** (learning_rate) | [0.0001, 0.0003]| Chosen for stable convergence. Lower rates avoid overshooting minima, while slightly higher rates accelerate learning without destabilization. |\n",
        "\n",
        "The tuning process balances model complexity and generalization, ensuring optimal feature extraction without overfitting or excessive computational burden. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define image shape globally\n",
        "image_shape = (128, 128, 3) \n",
        "\n",
        "# Function to define CNN model with hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    \"\"\"\n",
        "    Define a CNN model with hyperparameter tuning using Keras Tuner.\n",
        "\n",
        "    Parameters:\n",
        "    - hp: Keras Tuner search space\n",
        "\n",
        "    Returns:\n",
        "    - Compiled Keras model\n",
        "    \"\"\"\n",
        "    model = Sequential(\n",
        "        [\n",
        "            # Explicit Input Layer\n",
        "            Input(shape=image_shape),\n",
        "\n",
        "            # First convolutional block\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters_1\", values=[32, 64]),\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.001])),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Second convolutional block\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters_2\", values=[64, 128]),\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.001])),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Third convolutional block\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters_3\", values=[128, 256]),\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.001])),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Fourth convolutional block\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters_4\", values=[128, 256]),\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.001])),\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "            # Flatten Layer\n",
        "            Flatten(),\n",
        "\n",
        "            # Fully connected layer with regularization\n",
        "            Dense(128, activation=\"relu\", kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.0005]))),\n",
        "            Dropout(hp.Choice(\"dropout_rate\", values=[0.2, 0.3])),\n",
        "\n",
        "            # Output layer for binary classification\n",
        "            Dense(1, activation=\"sigmoid\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice(\"learning_rate\", values=[0.0001, 0.0003])\n",
        "        ),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Hyperparameter Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Search for the best hyperparameters using Keras Tuner’s RandomSearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",  # Optimize for highest validation accuracy\n",
        "    max_trials=7,  # Limits the number of model variations\n",
        "    executions_per_trial=1,  # Runs each model once\n",
        "    directory=\"keras_tuner_results\",\n",
        "    project_name=\"cnn_tuning\",\n",
        ")\n",
        "\n",
        "# Run hyperparameter search\n",
        "tuner.search(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=8,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)],  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve Best Hyperparameters & Print Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"\\n### Best Hyperparameters Found ###\")\n",
        "print(f\"Filters (Conv1): {best_hps.get('num_filters_1')}\")\n",
        "print(f\"Filters (Conv2): {best_hps.get('num_filters_2')}\")\n",
        "print(f\"Filters (Conv3): {best_hps.get('num_filters_3')}\")\n",
        "print(f\"Filters (Conv4): {best_hps.get('num_filters_4')}\")\n",
        "print(f\"L2 Regularization (Conv1): {best_hps.get('l2_reg')}\")\n",
        "print(f\"Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
        "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# Build the best model with selected hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Print the model summary\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Best Model & Store History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_tuned_cnn = best_model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)],  \n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the Best Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.save(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
        "print(\"\\nBest tuned CNN model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuned Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load & Evaluate the Tuned Model\n",
        "best_model = tf.keras.models.load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
        "\n",
        "test_loss_tuned, test_accuracy_tuned = best_model.evaluate(test_set)\n",
        "\n",
        "print(\"\\n### Tuned Model Evaluation ###\")\n",
        "print(f\"Test Accuracy: {test_accuracy_tuned:.4f}\")\n",
        "print(f\"Test Loss: {test_loss_tuned:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Training History to DataFrame (Tuned CNN)\n",
        "import pandas as pd\n",
        "\n",
        "df_history_tuned_cnn = pd.DataFrame(history_tuned_cnn.history)\n",
        "\n",
        "# Save history for later use\n",
        "df_history_tuned_cnn.to_csv(\"outputs/v1/history_tuned_cnn.csv\", index=False)\n",
        "print(\"Tuned CNN training history saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Learning Curve (Loss & Accuracy) for Tuned CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot Loss Curve\n",
        "df_history_tuned_cnn[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{file_path}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy Curve\n",
        "df_history_tuned_cnn[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{file_path}/model_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix & Classification Report for Tuned CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_dir = \"outputs/v1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to Generate Confusion Matrix\n",
        "def generate_confusion_matrix(y_true, y_pred, label_map, set_name):\n",
        "    \"\"\"\n",
        "    Generates, displays, and saves a static confusion matrix.\n",
        "    \n",
        "    Parameters:\n",
        "    - y_true: Actual class labels\n",
        "    - y_pred: Predicted class labels\n",
        "    - label_map: List of class names\n",
        "    - set_name: Dataset name (Train, Validation, Test)\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=label_map, columns=label_map)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5)\n",
        "    plt.title(f\"Confusion Matrix - {set_name} Set\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and show confusion matrix\n",
        "    save_path = os.path.join(output_dir, f\"confusion_matrix_{set_name.lower()}.png\")\n",
        "    plt.savefig(save_path, dpi=150)\n",
        "    plt.show()  # Display in the notebook\n",
        "    print(f\"Confusion Matrix saved at: {save_path}\")\n",
        "\n",
        "# Function to Generate Classification Report\n",
        "def generate_classification_report(y_true, y_pred, label_map, set_name):\n",
        "    \"\"\"\n",
        "    Generates, prints, and saves a classification report.\n",
        "    \n",
        "    Parameters:\n",
        "    - y_true: Actual class labels\n",
        "    - y_pred: Predicted class labels\n",
        "    - label_map: List of class names\n",
        "    - set_name: Dataset name (Train, Validation, Test)\n",
        "    \"\"\"\n",
        "    report = classification_report(y_true, y_pred, target_names=label_map)\n",
        "    \n",
        "    print(f\"\\n--- Classification Report: {set_name} Set ---\\n\")\n",
        "    print(report)\n",
        "\n",
        "    # Save report as a text file\n",
        "    report_path = os.path.join(output_dir, f\"classification_report_{set_name.lower()}.txt\")\n",
        "    with open(report_path, \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    print(f\"Classification report saved at: {report_path}\")\n",
        "\n",
        "# Function to Evaluate the Model\n",
        "def evaluate_model(generator, model, label_map, set_name, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluates model performance by generating a confusion matrix and classification report.\n",
        "    \n",
        "    Parameters:\n",
        "    - generator: Data generator (train, validation, or test)\n",
        "    - model: Trained model\n",
        "    - label_map: List of class names\n",
        "    - set_name: Dataset name (Train, Validation, Test)\n",
        "    - threshold: Probability threshold for classification (default: 0.5)\n",
        "    \"\"\"\n",
        "    y_true = generator.classes  # True labels\n",
        "    y_pred_probs = model.predict(generator)  # Model predictions (probabilities)\n",
        "    y_pred = (y_pred_probs > threshold).astype(int).flatten()  # Convert to class labels\n",
        "\n",
        "    print(f\"\\n#### {set_name} Set Evaluation ####\\n\")\n",
        "\n",
        "    # Generate and display confusion matrix\n",
        "    generate_confusion_matrix(y_true, y_pred, label_map, set_name)\n",
        "\n",
        "    # Generate and print classification report\n",
        "    generate_classification_report(y_true, y_pred, label_map, set_name)\n",
        "\n",
        "# Load the Tuned CNN Model\n",
        "tuned_model_path = \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
        "tuned_model = load_model(tuned_model_path)  \n",
        "\n",
        "# Get class labels from training set\n",
        "label_map = list(train_set.class_indices.keys())\n",
        "\n",
        "# Evaluate the Tuned Model on Train and Test Sets\n",
        "evaluate_model(train_set, tuned_model, label_map, \"Train\")\n",
        "evaluate_model(test_set, tuned_model, label_map, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Tuned CNN Model Evaluation Summary**\n",
        "\n",
        "#### **Training Set Performance**\n",
        "- **Accuracy:** 52%  \n",
        "- **Precision, Recall, F1-score:** 0.52 for both Healthy and Infected classes  \n",
        "- **Key Insight:** The training performance suggests that the model may not have fully learned class distinctions, as accuracy is close to random guessing.\n",
        "\n",
        "#### **Test Set Performance**\n",
        "- **Accuracy:** 100%  \n",
        "- **Precision, Recall, F1-score:** 1.00 for both Healthy and Infected classes  \n",
        "- **Key Insight:** The model perfectly classifies test samples, indicating **overfitting** on the training data.\n",
        "\n",
        "#### **Possible Concern**\n",
        "- The extreme difference in accuracy between training (52%) and test (100%) suggests **potential overfitting**, meaning the model might have memorized the test data rather than generalizing well.\n",
        "- Further analysis, such as **cross-validation or additional regularization**, may be necessary to ensure the model's robustness.\n",
        "\n",
        "**Conclusion:** While the Tuned CNN performs **perfectly on test data**, its poor training accuracy signals the need for further investigation to prevent overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Models (Base CNN vs Tuned CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Accuracy & Loss Bar Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Ensure correct variable names are used\n",
        "models = [\"Base CNN\", \"Tuned CNN\"]\n",
        "accuracy_values = [test_accuracy_base_cnn, test_accuracy_tuned]\n",
        "loss_values = [test_loss_base_cnn, test_loss_tuned]\n",
        "\n",
        "# Function to add value labels\n",
        "def add_value_labels(ax, values):\n",
        "    for i, v in enumerate(values):\n",
        "        ax.text(i, v + 0.02, f\"{v:.4f}\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "# Plot Accuracy Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.bar(models, accuracy_values, color=[\"blue\", \"green\"])\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.title(\"Accuracy Comparison: Base CNN vs. Tuned CNN\")\n",
        "plt.ylim(0, 1)  # Ensure accuracy is within [0,1]\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "add_value_labels(plt.gca(), accuracy_values)\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = plt.bar(models, loss_values, color=[\"red\", \"purple\"])\n",
        "plt.ylabel(\"Test Loss\")\n",
        "plt.title(\"Loss Comparison: Base CNN vs. Tuned CNN\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "add_value_labels(plt.gca(), loss_values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model Performance Comparison**\n",
        "#### **Accuracy Comparison**\n",
        "- **Base CNN:** Achieved lower test accuracy.  \n",
        "- **Tuned CNN:** Showed a significant accuracy improvement, indicating better feature extraction and generalization.  \n",
        "\n",
        "#### **Loss Comparison**\n",
        "- **Base CNN:** Higher test loss, suggesting inefficient learning and potential misclassifications.  \n",
        "- **Tuned CNN:** Drastically lower test loss, reinforcing that the model optimally fits the data with improved robustness.  \n",
        "\n",
        " **Conclusion:** The **Tuned CNN outperforms the Base CNN**, demonstrating **higher accuracy and lower loss**, making it a more reliable choice for real-world deployment.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Explainability & Feature Space Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## t-SNE Plot for Comparing Feature Separability of Base CNN and Tuned CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This t-SNE visualization represents the feature space of the test set as extracted from the Base CNN and Tuned CNN before classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Import Required Libraries\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "# Step 2: Load Both Models\n",
        "base_model_path = \"outputs/v1/mildew_detector_cnn.keras\"\n",
        "tuned_model_path = \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
        "\n",
        "base_model = load_model(base_model_path)\n",
        "tuned_model = load_model(tuned_model_path)\n",
        "\n",
        "# Function to Extract Features and Apply t-SNE\n",
        "def extract_tsne_features(model, test_set, model_name):\n",
        "    feature_extractor = Model(\n",
        "        inputs=model.layers[0].input, \n",
        "        outputs=model.get_layer(index=-2).output  # Extract from second-last layer\n",
        "    )\n",
        "    X_test_features = feature_extractor.predict(test_set)\n",
        "    y_test_labels = test_set.classes  \n",
        "\n",
        "    # Adjust Perplexity\n",
        "    num_samples = X_test_features.shape[0]\n",
        "    adjusted_perplexity = min(30, num_samples - 1)\n",
        "\n",
        "    # Apply t-SNE\n",
        "    tsne = TSNE(n_components=2, perplexity=adjusted_perplexity, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(X_test_features)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_tsne = pd.DataFrame(X_tsne, columns=[\"t-SNE1\", \"t-SNE2\"])\n",
        "    df_tsne[\"Label\"] = y_test_labels  \n",
        "\n",
        "    # Define Class Mapping\n",
        "    label_map = {v: k for k, v in train_set.class_indices.items()}  \n",
        "    df_tsne[\"Label\"] = df_tsne[\"Label\"].map(label_map)\n",
        "\n",
        "    return df_tsne\n",
        "\n",
        "# Step 3: Extract Features for Both Models\n",
        "df_tsne_base = extract_tsne_features(base_model, test_set, \"Base CNN\")\n",
        "df_tsne_tuned = extract_tsne_features(tuned_model, test_set, \"Tuned CNN\")\n",
        "\n",
        "# Step 4: Plot t-SNE Results (Side-by-Side)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# t-SNE for Base CNN\n",
        "sns.scatterplot(ax=axes[0], data=df_tsne_base, x=\"t-SNE1\", y=\"t-SNE2\", hue=\"Label\", palette=[\"blue\", \"orange\"], alpha=0.7)\n",
        "axes[0].set_title(\"t-SNE: Base CNN\")\n",
        "axes[0].grid(True)\n",
        "\n",
        "# t-SNE for Tuned CNN (Different Color Scheme)\n",
        "sns.scatterplot(ax=axes[1], data=df_tsne_tuned, x=\"t-SNE1\", y=\"t-SNE2\", hue=\"Label\", palette=[\"green\", \"red\"], alpha=0.7)\n",
        "axes[1].set_title(\"t-SNE: Tuned CNN\")\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remark**\n",
        "\n",
        "The t-SNE visualization highlights the improvement in feature separability after hyperparameter tuning.\n",
        "- Base CNN: Shows partial separation between Healthy and Infected samples but with noticeable overlap, indicating difficulty in distinguishing the classes.\n",
        "- Tuned CNN: Demonstrates clearer feature clustering, suggesting enhanced feature extraction and improved classification performance.\n",
        "\n",
        "Conclusion: The Tuned CNN extracts more distinguishable features, contributing to its higher accuracy compared to the Base CNN. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saliency Maps for Tuned CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saliency maps help visualize which parts of an image were most influential in the model’s classification decision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2  # OpenCV for better heatmap visualization\n",
        "\n",
        "# Load the Tuned CNN Model\n",
        "tuned_model_path = \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
        "tuned_model = tf.keras.models.load_model(tuned_model_path)\n",
        "\n",
        "# Define a Function to Compute and Enhance Saliency Maps\n",
        "def compute_saliency_map(model, image, class_index):\n",
        "    \"\"\"\n",
        "    Computes a Saliency Map to highlight important pixels influencing the model's decision.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained CNN model\n",
        "    - image: Input image (single sample)\n",
        "    - class_index: Target class index (0 for Healthy, 1 for Infected)\n",
        "\n",
        "    Returns:\n",
        "    - Enhanced saliency map as a NumPy array\n",
        "    \"\"\"\n",
        "    image = tf.convert_to_tensor(image[None], dtype=tf.float32)  # Add batch dimension\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        preds = model(image)\n",
        "        loss = preds[:, class_index]  # Focus on the target class\n",
        "\n",
        "    grads = tape.gradient(loss, image)[0]  # Compute gradients\n",
        "    saliency = np.max(np.abs(grads), axis=-1)  # Take max across color channels\n",
        "\n",
        "    # Normalize Saliency Map\n",
        "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-8)  # Normalize between 0-1\n",
        "\n",
        "    # Apply Exponential Scaling to Enhance Weak Signals\n",
        "    saliency = np.power(saliency, 3)  # Amplify small differences\n",
        "\n",
        "    # Convert to 8-bit (0-255) for Better Visualization\n",
        "    saliency = (saliency * 255).astype(np.uint8)\n",
        "\n",
        "    # Apply Histogram Equalization to Improve Contrast\n",
        "    saliency = cv2.equalizeHist(saliency)\n",
        "\n",
        "    # Apply a Stronger Colormap for More Visible Heatmap\n",
        "    saliency_colored = cv2.applyColorMap(saliency, cv2.COLORMAP_HOT)  # Use 'HOT' colormap for high contrast\n",
        "\n",
        "    return saliency_colored\n",
        "\n",
        "# Select a Test Image\n",
        "sample_index = 7  # Adjust if needed\n",
        "X_test_batch, y_test_batch = next(iter(test_set))  # Extract a batch\n",
        "sample_image = X_test_batch[sample_index]  # Select one test image\n",
        "sample_label = int(y_test_batch[sample_index])  # Convert label to integer\n",
        "\n",
        "# Compute Saliency Map\n",
        "saliency = compute_saliency_map(tuned_model, sample_image, class_index=sample_label)\n",
        "\n",
        "# Display the Original Image and Enhanced Saliency Map\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Show Original Image \n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(np.clip(sample_image * 255, 0, 255).astype(\"uint8\"))  \n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Original Image (Enhanced Contrast)\")\n",
        "\n",
        "# Show Strongly Enhanced Saliency Map\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(saliency, cv2.COLOR_BGR2RGB))  # Convert OpenCV BGR to RGB\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Strongly Enhanced Saliency Map\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remark**\n",
        "\n",
        "The Saliency Map highlights the most influential regions that guided the CNN’s classification decisions.\n",
        "\n",
        "- Bright yellow/orange areas indicate the regions the model prioritized for classification.\n",
        "- The model focuses on specific patterns and textures rather than random noise, confirming its ability to extract meaningful features.\n",
        "- Saliency regions vary across images, suggesting that the CNN adapts dynamically based on the input.\n",
        "\n",
        "This analysis reinforces the model’s interpretability, demonstrating that its predictions are based on relevant visual features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Model Selection & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Compare Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Both Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_cnn_model = load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
        "print(\"Tuned CNN Model Loaded Successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd\n",
        "\n",
        "# Load the base CNN model\n",
        "base_cnn_model = load_model(\"outputs/v1/mildew_detector_base_cnn.keras\")\n",
        "\n",
        "# Load the best tuned CNN model\n",
        "tuned_cnn_model = load_model(\"outputs/v1/mildew_detector_tuned_cnn.keras\")\n",
        "\n",
        "# Load training history DataFrames\n",
        "df_history_base_cnn = pd.read_csv(\"outputs/v1/history_base_cnn.csv\")\n",
        "df_history_tuned_cnn = pd.read_csv(\"outputs/v1/history_tuned_cnn.csv\")\n",
        "\n",
        "print(\"Both models and their training histories have been loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Both Models On the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate both models\n",
        "base_test_loss, base_test_accuracy = base_cnn_model.evaluate(test_set, verbose=0)\n",
        "tuned_test_loss, tuned_test_accuracy = tuned_cnn_model.evaluate(test_set, verbose=0)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"\\n### Base CNN Evaluation ###\")\n",
        "print(f\"Test Accuracy: {base_test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {base_test_loss:.4f}\")\n",
        "\n",
        "print(\"\\n### Tuned CNN Evaluation ###\")\n",
        "print(f\"Test Accuracy: {tuned_test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {tuned_test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Model Performance in a Structured Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display \n",
        "\n",
        "# Create the comparison dataframe\n",
        "comparison_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Model\": [\"Base CNN\", \"Tuned CNN\"],\n",
        "        \"Test Accuracy\": [base_test_accuracy, tuned_test_accuracy],\n",
        "        \"Test Loss\": [base_test_loss, tuned_test_loss],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Display results\n",
        "display(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select the Best Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the best model: prioritize accuracy first, then lower loss as tiebreaker\n",
        "if tuned_test_accuracy > base_test_accuracy:\n",
        "    best_model_name = \"Tuned CNN\"\n",
        "elif tuned_test_accuracy == base_test_accuracy and tuned_test_loss < base_test_loss:\n",
        "    best_model_name = \"Tuned CNN\"\n",
        "else:\n",
        "    best_model_name = \"Base CNN\"\n",
        "\n",
        "# Assign correct model path\n",
        "best_model_path = (\n",
        "    \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
        "    if best_model_name == \"Tuned CNN\"\n",
        "    else \"outputs/v1/mildew_detector_base_cnn.keras\"\n",
        ")\n",
        "\n",
        "# Print final selection\n",
        "print(\"\\n### Best Model Selected ###\")\n",
        "print(f\"Model: {best_model_name}\")\n",
        "print(f\"Test Accuracy: {tuned_test_accuracy:.4f} (Tuned) | {base_test_accuracy:.4f} (Base)\")\n",
        "print(f\"Test Loss: {tuned_test_loss:.4f} (Tuned) | {base_test_loss:.4f} (Base)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assess Model Efficiency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Complexity Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get model parameter counts\n",
        "base_cnn_params = base_cnn_model.count_params() / 1e6  # Convert to millions\n",
        "tuned_cnn_params = tuned_cnn_model.count_params() / 1e6  # Convert to millions\n",
        "\n",
        "# Define Model Names and Parameter Counts\n",
        "models = [\"Base CNN\", \"Tuned CNN\"]\n",
        "params = [base_cnn_params, tuned_cnn_params]\n",
        "\n",
        "# Plot Model Complexity (Parameter Count)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, params, color=[\"blue\", \"orange\"])\n",
        "plt.ylabel(\"Parameter Count (Millions)\")\n",
        "plt.title(\"Model Complexity: Parameter Count Comparison\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Model Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Get model sizes (in MB)\n",
        "base_cnn_size = os.path.getsize(\"outputs/v1/mildew_detector_base_cnn.keras\") / (1024 * 1024)\n",
        "tuned_cnn_size = os.path.getsize(\"outputs/v1/mildew_detector_cnn_tuned.keras\") / (1024 * 1024)\n",
        "\n",
        "# Define Model Names and Sizes\n",
        "models = [\"Base CNN\", \"Tuned CNN\"]\n",
        "sizes = [base_cnn_size, tuned_cnn_size]\n",
        "\n",
        "# Plot Model Size Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, sizes, color=[\"blue\", \"orange\"])\n",
        "plt.ylabel(\"Model Size (MB)\")\n",
        "plt.title(\"Model Storage Comparison\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computational Performance Cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Measure Inference Time\n",
        "def measure_inference_time(model, test_set):\n",
        "    sample_input, _ = next(iter(test_set))  # Get one batch\n",
        "    start_time = time.time()\n",
        "    _ = model.predict(sample_input)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time  # Return execution time\n",
        "\n",
        "# Compute Inference Time\n",
        "base_cnn_time = measure_inference_time(base_cnn_model, test_set)\n",
        "tuned_cnn_time = measure_inference_time(tuned_cnn_model, test_set)\n",
        "\n",
        "# Define Model Names and Inference Times\n",
        "models = [\"Base CNN\", \"Tuned CNN\"]\n",
        "times = [base_cnn_time, tuned_cnn_time]\n",
        "\n",
        "# Plot Computation Time Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, times, color=[\"blue\", \"orange\"])\n",
        "plt.ylabel(\"Inference Time (Seconds per Batch)\")\n",
        "plt.title(\"Computation Time Comparison\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check Business Case Requirement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the required accuracy threshold (example: 90%)\n",
        "required_accuracy = 0.90  \n",
        "\n",
        "# Evaluate final model\n",
        "final_model = load_model(best_model_path)\n",
        "final_test_loss, final_test_accuracy = final_model.evaluate(test_set, verbose=0)\n",
        "\n",
        "# Print Performance Evaluation Summary\n",
        "print(\"\\n### Business Case Requirement Check ###\")\n",
        "print(f\"Required Accuracy: {required_accuracy * 100:.2f}%\")\n",
        "print(f\"Final Model Achieved Accuracy: {final_test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Decision\n",
        "if final_test_accuracy >= required_accuracy:\n",
        "    print(\"\\nThe model meets the business performance requirement.\")\n",
        "else:\n",
        "    print(\"\\nThe model does NOT meet the business requirement. Consider further tuning.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \tFinal Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Model Selection & Evaluation (Written Explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the Best Model for Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model as final for deployment\n",
        "final_model_path = \"outputs/v1/final_mildew_detector.keras\"\n",
        "final_model.save(final_model_path)\n",
        "\n",
        "print(\"\\n### Best Model Saved for Deployment ###\")\n",
        "print(f\"Model: {best_model_name}\")\n",
        "print(f\"Saved at: {final_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select & Display a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to select and display a sample image\n",
        "def load_sample_image(test_set, sample_idx=0):\n",
        "    \"\"\"\n",
        "    Select a sample image from the test set and display it.\n",
        "    \"\"\"\n",
        "    test_images, test_labels = next(iter(test_set))  # Get batch of images\n",
        "    sample_image = test_images[sample_idx]  # Select one image\n",
        "    sample_label = test_labels[sample_idx]  # Get its label\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(sample_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Sample Image - {'Healthy' if sample_label == 0 else 'Infected'}\")\n",
        "    plt.show()\n",
        "\n",
        "    return sample_image, sample_label\n",
        "\n",
        "\n",
        "# Load and display a sample image from the test set\n",
        "sample_image, sample_label = load_sample_image(test_set, sample_idx=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predict on New Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load & Predict on Sample Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load test images and classify them using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the final model\n",
        "model = load_model(\"outputs/v1/final_mildew_detector.keras\")\n",
        "\n",
        "# Select an image by specifying its index (pointer)\n",
        "pointer = 60\n",
        "label = labels[1]  # Selecting an 'Infected' leaf image\n",
        "\n",
        "# Load the selected image and resize it\n",
        "pil_image = image.load_img(\n",
        "    test_path + \"/\" + label + \"/\" + os.listdir(test_path + \"/\" + label)[pointer],\n",
        "    target_size=image_shape,\n",
        "    color_mode=\"rgb\",\n",
        ")\n",
        "\n",
        "# Convert the image to an array and normalize it\n",
        "my_image = image.img_to_array(pil_image) / 255.0\n",
        "my_image = np.expand_dims(my_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Make a prediction\n",
        "pred_proba = model.predict(my_image)[0, 0]  # Extract prediction probability\n",
        "\n",
        "# Map indices to class labels\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}  # Reverse mapping\n",
        "pred_class = target_map[int(pred_proba > 0.5)]  # **Fixed: Ensure correct mapping**\n",
        "\n",
        "# Adjust probability if needed\n",
        "if pred_class == target_map[0]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "# Display results\n",
        "print(f\"Image shape: {pil_image.size}\")\n",
        "print(f\"Image mode: {pil_image.mode}\")\n",
        "print(f\"Predicted class: {pred_class}\")\n",
        "print(f\"Prediction probability: {pred_proba:.4f}\")\n",
        "\n",
        "# Show the image\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a list of pointers\n",
        "pointers = [10, 30, 50, 70]\n",
        "label = labels[1]  # 'Infected' or 'Healthy'\n",
        "\n",
        "fig, axes = plt.subplots(1, len(pointers), figsize=(15, 5))\n",
        "\n",
        "for i, pointer in enumerate(pointers):\n",
        "    img_list = os.listdir(test_path + \"/\" + label)\n",
        "\n",
        "    if pointer >= len(img_list):\n",
        "        print(f\"Skipping pointer {pointer}, index out of range.\")\n",
        "        continue\n",
        "\n",
        "    img_path = test_path + \"/\" + label + \"/\" + img_list[pointer]\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(128, 128))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = model.predict(img_array)[0, 0]\n",
        "    pred_class = \"Healthy\" if pred < 0.5 else \"Infected\"\n",
        "\n",
        "    # Plot the image and prediction result\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"{pred_class}\\nProb: {pred:.4f}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this project, we successfully developed a deep learning model to detect Powdery Mildew on Cherry Leaves using a structured, beginner-friendly approach.\n",
        "\n",
        "## Key Achievements\n",
        "- Baseline CNN Implementation → Developed an initial CNN model to establish a performance benchmark.\n",
        "- Optimized Hyperparameter Tuning → Applied systematic tuning (adjusting filters, dropout, learning rate, and L2 regularization) to enhance model performance while balancing computational efficiency.\n",
        "- Model Evaluation & Comparison → Assessed the baseline and optimized CNN models based on accuracy, loss, and generalization ability.\n",
        "- Explainability with Saliency Maps → Visualized important regions influencing the model’s predictions, enhancing interpretability.\n",
        "- Final Model Selection → The Hyperparameter-Tuned CNN was chosen based on its superior accuracy and robustness for real-world deployment.\n",
        "\n",
        "## Next Steps: Model Deployment\n",
        "\n",
        "The next step is to integrate the optimized CNN model into a user-friendly application that allows real-time classification of leaf images.\n",
        "\n",
        "Deployment Plan\n",
        "- Develop an Interactive Web App → Implement a Streamlit-based interface where users can upload leaf images for classification.\n",
        "- Integrate the Tuned CNN Model → Load the trained model to process new images and predict mildew presence.\n",
        "- Deploy on a Cloud Platform → Host the web application using Streamlit and Heroku for accessibility.\n",
        "\n",
        "This deployment will enable real-time detection of powdery mildew, aiding efficient disease monitoring and automated plantation management.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
