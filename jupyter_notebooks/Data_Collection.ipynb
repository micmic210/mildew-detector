{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "1. Import necessary packages and configure the working directory.\n",
        "2. Authenticate and retrieve the mildew dataset from Kaggle.\n",
        "3. Prepare the dataset by organizing it into train, validation, and test splits.\n",
        "4. Ensure data integrity by removing any non-image files.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- Kaggle JSON file: Used for authentication and dataset download.\n",
        "- Dataset sourse: The mildew dataset hosted on Kaggle.\n",
        "- Local directories: Structure for storing and splitting data.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Raw Dataset: Downloaded and unzipped into the specified folder\n",
        "- Cleaned Dataset: Non-image files removed for consistency.\n",
        "- Structured Data: Split into training (70%), validation (10%), and testing (20%) sets, organized in respective directories.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- These steps are critical to ensure the dataset is properly prepared for model training and evaluation. By structuring and cleaning the data, we minimize errors during training and improve model accuracy. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change Working Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Working Directory & File Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir('/workspaces/mildew-detector')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "#### Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Install Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change the Kaggle configuration directory to the current working directory and set permissions for the Kaggle authentication JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Dataset and Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/mildew_dataset\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unzip the Downloaded File and Delete the ZIP File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/cherry-leaves.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    \"\"\"\n",
        "    Remove files that are not images from the dataset directory. \n",
        "    \"\"\"\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(my_data_dir + '/' + folder)\n",
        "        # print(files)\n",
        "        i = []\n",
        "        j = []\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location)  \n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "                pass\n",
        "        print(f\"Folder: {folder} - has image file\", len(j))\n",
        "        print(f\"Folder: {folder} - has non-image file\", len(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detect and Remove Corrupt Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_corrupt_images(directory):\n",
        "    corrupt_images = []\n",
        "\n",
        "    for folder in os.listdir(directory):\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                try:\n",
        "                    img = Image.open(img_path)  # Try opening the image\n",
        "                    img.verify()  # Verify image integrity\n",
        "                except (IOError, SyntaxError):\n",
        "                    print(f\"Corrupt image detected: {img_path}\")\n",
        "                    corrupt_images.append(img_path)\n",
        "\n",
        "    return corrupt_images\n",
        "\n",
        "# Define your dataset directory\n",
        "dataset_path = \"inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "# Run check on the extracted dataset (Healthy & Infected folders)\n",
        "corrupt_images = check_corrupt_images(dataset_path)\n",
        "\n",
        "print(f\"Total corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Data into Train, Validation, and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):    \n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation, and test sets.\n",
        "    \"\"\"\n",
        "    # Validate that the sum of train, validation, and test ratios equals 1.0\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio!= 1.0:\n",
        "        print(\"Error: train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # Get the class labels in the dataset directory \n",
        "    labels = os.listdir(my_data_dir)  \n",
        "\n",
        "    # Create 'train', 'validation', and 'test' folders with class subfolders\n",
        "    for folder in ['train', 'validation', 'test']:\n",
        "        for label in labels:\n",
        "            os.makedirs(name=os.path.join(my_data_dir, folder, label), exist_ok=True)\n",
        "\n",
        "    # Iterate through each class label\n",
        "    for label in labels:\n",
        "        # Get the list of files in the current class label directory\n",
        "        files = os.listdir(os.path.join(my_data_dir, label))\n",
        "        random.shuffle(files)\n",
        "        # Calculate the number of files for train, validation, and test sets\n",
        "        train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "        validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "        count = 1\n",
        "        for file_name in files:\n",
        "            if count <= train_set_files_qty:\n",
        "                # Move the file to the 'train' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'train', label, file_name))\n",
        "\n",
        "            elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                # Move the file to the 'validation' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'validation', label, file_name))\n",
        "            else:\n",
        "                # Move the file to the 'test' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'test', label, file_name))\n",
        "\n",
        "            count += 1\n",
        "        # Remove the original class directory after all files are moved\n",
        "        os.rmdir(os.path.join(my_data_dir, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(my_data_dir=f\"inputs/mildew_dataset/cherry-leaves\",\n",
        "                                   train_set_ratio=0.7,\n",
        "                                   validation_set_ratio=0.1,\n",
        "                                   test_set_ratio=0.2\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Count Images in Each Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "sets = ['train', 'test', 'validation']\n",
        "labels = ['Healthy', 'Infected']  \n",
        "\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f'inputs/mildew_dataset/cherry-leaves/{set_name}/{label}' \n",
        "        try:\n",
        "            number_of_files = len(os.listdir(path))\n",
        "            print(f'There are {number_of_files} images in {set_name}/{label}')\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Directory '{path}' not found.\")\n",
        "\n",
        "# Compute total number of images across all datasets (train, validation, test)\n",
        "total_images = 0\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f'inputs/mildew_dataset/cherry-leaves/{set_name}/{label}'  \n",
        "        try:\n",
        "            total_images += len(os.listdir(path))\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "print(f\"\\nTotal number of images: {total_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook successfully handled data collection and preprocessing for the powdery mildew detection project. The dataset was:\n",
        "\n",
        "- Downloaded from Kaggle using authentication.\n",
        "- Cleaned by removing non-image files.\n",
        "- Organized into train (70%), validation (10%), and test (20%) sets.\n",
        "- Verified for integrity by counting images in each set.\n",
        "\n",
        "## Next Steps:\n",
        "Data Exploration & Visualization:\n",
        "- Analyze class distributions and dataset balance.\n",
        "- Generate image samples to check quality.\n",
        "- Compute image dimensions for standardization.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
