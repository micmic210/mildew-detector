{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "1. Import necessary packages and configure the working directory.\n",
        "2. Authenticate and retrieve the mildew dataset from Kaggle.\n",
        "3. Prepare the dataset by organizing it into train, validation, and test splits.\n",
        "4. Ensure data integrity by removing any non-image files.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- Kaggle JSON file: Used for authentication and dataset download.\n",
        "- Dataset sourse: The mildew dataset hosted on Kaggle.\n",
        "- Local directories: Structure for storing and splitting data.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Raw Dataset: Downloaded and unzipped into the specified folder\n",
        "- Cleaned Dataset: Non-image files removed for consistency.\n",
        "- Structured Data: Split into training (70%), validation (10%), and testing (20%) sets, organized in respective directories.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- These steps are critical to ensure the dataset is properly prepared for model training and evaluation. By structuring and cleaning the data, we minimize errors during training and improve model accuracy. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change Working Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Working Directory & File Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/mildew-detector/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/workspaces/mildew-detector')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "#### Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/mildew-detector'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Install Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /home/cistudent/.local/lib/python3.12/site-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/cistudent/.local/lib/python3.12/site-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /home/cistudent/.local/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /home/cistudent/.local/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->kaggle) (3.10)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change the Kaggle configuration directory to the current working directory and set permissions for the Kaggle authentication JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Dataset and Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/codeinstitute/cherry-leaves\n",
            "License(s): unknown\n",
            "Downloading cherry-leaves.zip to inputs/mildew_dataset\n",
            " 95%|███████████████████████████████████▉  | 52.0M/55.0M [00:01<00:00, 43.4MB/s]\n",
            "100%|██████████████████████████████████████| 55.0M/55.0M [00:02<00:00, 28.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/mildew_dataset\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unzip the Downloaded File and Delete the ZIP File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/cherry-leaves.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove Non-Image Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder: Healthy - has image files: 2104\n",
            "Folder: Healthy - removed non-image files: 0\n",
            "Folder: Infected - has image files: 2104\n",
            "Folder: Infected - removed non-image files: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def remove_non_image_file(my_data_dir):\n",
        "    \"\"\"\n",
        "    Remove files that are not images from the dataset directory.\n",
        "    \"\"\"\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(os.path.join(my_data_dir, folder))\n",
        "        i = []  # List to count removed non-image files\n",
        "        j = []  # List to count valid image files\n",
        "        for given_file in files:\n",
        "            file_location = os.path.join(my_data_dir, folder, given_file)\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                os.remove(file_location)  # Remove non-image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "\n",
        "        print(f\"Folder: {folder} - has image files:\", len(j))\n",
        "        print(f\"Folder: {folder} - removed non-image files:\", len(i))\n",
        "\n",
        "# Define dataset directory\n",
        "dataset_path = \"inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "# Run data cleaning (remove non-image files)\n",
        "remove_non_image_file(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detect and Remove Corrupt Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total corrupt images removed: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_corrupt_images(directory):\n",
        "    \"\"\"\n",
        "    Detect and remove corrupt images from the dataset.\n",
        "    \"\"\"\n",
        "    corrupt_images = []\n",
        "\n",
        "    for folder in os.listdir(directory):\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                try:\n",
        "                    img = Image.open(img_path)  # Try opening the image\n",
        "                    img.verify()  # Verify image integrity\n",
        "                except (IOError, SyntaxError):\n",
        "                    print(f\"Removing corrupt image: {img_path}\")\n",
        "                    corrupt_images.append(img_path)\n",
        "                    os.remove(img_path)  # Remove corrupt image\n",
        "\n",
        "    print(f\"Total corrupt images removed: {len(corrupt_images)}\")\n",
        "    return corrupt_images\n",
        "\n",
        "# Run corruption check\n",
        "corrupt_images = check_corrupt_images(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Data into Train, Validation, and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):    \n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation, and test sets.\n",
        "    \"\"\"\n",
        "    # Validate that the sum of train, validation, and test ratios equals 1.0\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio!= 1.0:\n",
        "        print(\"Error: train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # Get the class labels in the dataset directory \n",
        "    labels = os.listdir(my_data_dir)  \n",
        "\n",
        "    # Create 'train', 'validation', and 'test' folders with class subfolders\n",
        "    for folder in ['train', 'validation', 'test']:\n",
        "        for label in labels:\n",
        "            os.makedirs(name=os.path.join(my_data_dir, folder, label), exist_ok=True)\n",
        "\n",
        "    # Iterate through each class label\n",
        "    for label in labels:\n",
        "        # Get the list of files in the current class label directory\n",
        "        files = os.listdir(os.path.join(my_data_dir, label))\n",
        "        random.shuffle(files)\n",
        "        # Calculate the number of files for train, validation, and test sets\n",
        "        train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "        validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "        count = 1\n",
        "        for file_name in files:\n",
        "            if count <= train_set_files_qty:\n",
        "                # Move the file to the 'train' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'train', label, file_name))\n",
        "\n",
        "            elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                # Move the file to the 'validation' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'validation', label, file_name))\n",
        "            else:\n",
        "                # Move the file to the 'test' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'test', label, file_name))\n",
        "\n",
        "            count += 1\n",
        "        # Remove the original class directory after all files are moved\n",
        "        os.rmdir(os.path.join(my_data_dir, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(my_data_dir=f\"inputs/mildew_dataset/cherry-leaves\",\n",
        "                                   train_set_ratio=0.7,\n",
        "                                   validation_set_ratio=0.1,\n",
        "                                   test_set_ratio=0.2\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Count Images in Each Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1472 images in train/Healthy\n",
            "There are 1472 images in train/Infected\n",
            "There are 422 images in test/Healthy\n",
            "There are 422 images in test/Infected\n",
            "There are 210 images in validation/Healthy\n",
            "There are 210 images in validation/Infected\n",
            "\n",
            "Total number of images: 4208\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "sets = ['train', 'test', 'validation']\n",
        "labels = ['Healthy', 'Infected']  \n",
        "\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f'inputs/mildew_dataset/cherry-leaves/{set_name}/{label}' \n",
        "        try:\n",
        "            number_of_files = len(os.listdir(path))\n",
        "            print(f'There are {number_of_files} images in {set_name}/{label}')\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Directory '{path}' not found.\")\n",
        "\n",
        "# Compute total number of images across all datasets (train, validation, test)\n",
        "total_images = 0\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f'inputs/mildew_dataset/cherry-leaves/{set_name}/{label}'  \n",
        "        try:\n",
        "            total_images += len(os.listdir(path))\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "print(f\"\\nTotal number of images: {total_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook successfully handled data collection and preprocessing for the powdery mildew detection project. The dataset was:\n",
        "\n",
        "- Downloaded from Kaggle using authentication.\n",
        "- Cleaned by removing non-image files.\n",
        "- Organized into train (70%), validation (10%), and test (20%) sets.\n",
        "- Verified for integrity by counting images in each set.\n",
        "\n",
        "## Next Steps:\n",
        "Data Exploration & Visualization:\n",
        "- Analyze class distributions and dataset balance.\n",
        "- Generate image samples to check quality.\n",
        "- Compute image dimensions for standardization.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
