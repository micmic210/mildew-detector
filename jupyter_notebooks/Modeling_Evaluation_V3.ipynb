{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **MOBILENETV2 Modeling and Evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
    "- Build and evaluate models: Implement a baseline CNN model, refine it through hyperparameter tuning, and assess performance.\n",
    "- Analyze model effectiveness: Use Saliency Maps and t-SNE visualization to interpret model predictions and feature separability.\n",
    "- Compare model performance: Select the best model based on accuracy, loss, and efficiency for real-world deployment.\n",
    "- Prepare for deployment: Save the optimized model for integration into a Streamlit web app hosted on Heroku.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Dataset\n",
    "- inputs/mildew_dataset/cherry-leaves/train\n",
    "- inputs/mildew_dataset/cherry-leaves/validation\n",
    "- inputs/mildew_dataset/cherry-leaves/test\n",
    "\n",
    "Precomputed Features (from Data Visualization Notebook)\n",
    "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
    "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
    "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Data Processing & Visualization\n",
    "- Dataset Distribution Plot → Confirmed balanced data split across training, validation, and test sets.\n",
    "- Data Augmentation Visualization → Showcased applied transformations, including rotation, flipping, and zooming.\n",
    "Model Training & Optimization\n",
    "- Baseline CNN Model → Implemented a standard CNN to establish initial performance.\n",
    "- Hyperparameter-Tuned CNN → Optimized model performance using Keras Tuner (adjusting filters, dropout, learning rate, and L2 regularization).\n",
    "- Best Model Selection → Chose the Tuned CNN based on test accuracy and generalization ability.\n",
    "- Saved Trained Models → Final model stored for Streamlit integration and deployment on Heroku.\n",
    "Model Evaluation & Explainability\n",
    "- Learning Curves → Visualized loss and accuracy trends over epochs.\n",
    "- Confusion Matrices → Displayed classification performance for train, validation, and test sets.\n",
    "- Classification Reports → Provided precision, recall, and F1-score analysis.\n",
    "- Saliency Maps → Highlighted regions in images that influenced the model’s predictions.\n",
    "- Feature Space Visualization→ Compared Baseline CNN and Tuned CNN feature separability.\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "- Business Impact: The trained model can assist in early detection of powdery mildew, reducing manual inspection time and improving plantation monitoring efficiency.\n",
    "- Data-Driven Enhancements: Model improvements were guided by data preprocessing insights, including class balance validation.\n",
    "- Deployment Readiness: The best model was optimized and prepared for integration into a Streamlit web app for real-world application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/mildew-detector')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "#### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "## Set Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directories\n",
    "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
    "train_path = os.path.join(my_data_dir, 'train')\n",
    "val_path = os.path.join(my_data_dir, 'validation')\n",
    "test_path = os.path.join(my_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v3'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels for the images\n",
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images in Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dictionary\n",
    "data = {\n",
    "    'Set': [],\n",
    "    'Label': [],\n",
    "    'Frequency': []\n",
    "}\n",
    "\n",
    "# Define dataset folders\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each dataset split and count images\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        path = os.path.join(my_data_dir, folder, label)\n",
    "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "        print(f\" {folder}/{label}: {num_images} images\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_freq = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart - Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.title(\"Image Distribution in Dataset\")\n",
    "plt.xlabel(\"Dataset Split\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow/Keras ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize ImageDataGenerator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation for Training Set\n",
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Training Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Validation Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Augmented Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Augmented Images in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images_grid(data_generator, num_images=10):\n",
    "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
    "    img_batch, label_batch = next(data_generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
    "        ax.imshow(img_batch[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image grid\n",
    "plot_augmented_images_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetv2():\n",
    "    \"\"\"\n",
    "    Builds a lightweight MobileNetV2-based model for binary classification.\n",
    "    Returns:\n",
    "        model (Sequential): A compiled Keras model.\n",
    "    \"\"\"\n",
    "    # Load MobileNetV2 with pre-trained weights, excluding the top classification layer\n",
    "    base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "    # Freeze base model layers to retain pre-trained features\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build the classification head\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation=\"relu\"),  # Simple dense layer\n",
    "        Dropout(0.3),  # Dropout for regularization\n",
    "        Dense(2, activation=\"softmax\")  # Softmax for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile with default settings\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and check the model summary\n",
    "mobilenet_model = create_mobilenetv2()\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set EarlyStopping callback\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit MobileNetV2 model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Mobilenet model\n",
    "mobilenet_model = create_mobilenetv2()\n",
    "\n",
    "# Train the base Mobilenetmodel\n",
    "history_mobilenet = mobilenet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained base CNN model\n",
    "mobilenet_model.save(\"outputs/v3/mildew_detector_mobilenetv2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Mobile on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the MobileNetV2 Model\n",
    "test_loss_mobilenet, test_accuracy_mobilenet = mobilenet_model.evaluate(test_generator)\n",
    "\n",
    "# Print Evaluation Results\n",
    "print(f\"Test Accuracy (MobileNetV2): {test_accuracy_mobilenet:.4f}\")\n",
    "print(f\"Test Loss (MobileNetV2): {test_loss_mobilenet:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training History for Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training history of MobileNetV2 to DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df_history_mobilenet = pd.DataFrame(history_mobilenet.history)\n",
    "\n",
    "# Save history for later use\n",
    "df_history_mobilenet.to_csv(\"outputs/v3/history_mobilenet.csv\", index=False)\n",
    "print(\"MobileNetV2 training history saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning Curve (Loss & Accuracy) for Base CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert history to DataFrame for easy plotting\n",
    "import pandas as pd\n",
    "\n",
    "df_history_mobilenet = pd.DataFrame(mobilenet_model.history.history)\n",
    "\n",
    "# Loss Curve\n",
    "df_history_mobilenet[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
    "plt.title(\"Loss - MobileNetV2\")\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/v3/mobilenet_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Curve\n",
    "df_history_mobilenet[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
    "plt.title(\"Accuracy - MobileNetV2\")\n",
    "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/v3/mobilenet_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix & Classification Report (Train & Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Confusion Matrix & Classification Report Functions\n",
    "def generate_confusion_matrix(y_true, y_pred, label_map, set_name):\n",
    "    \"\"\"\n",
    "    Generates, displays, and saves a static confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=label_map, columns=label_map)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5)\n",
    "    plt.title(f\"Confusion Matrix - {set_name} Set\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show confusion matrix\n",
    "    save_path = os.path.join(output_dir, f\"confusion_matrix_{set_name.lower()}.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"Confusion Matrix saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_report(y_true, y_pred, label_map, set_name):\n",
    "    \"\"\"\n",
    "    Generates, prints, and saves a classification report.\n",
    "    \"\"\"\n",
    "    report = classification_report(y_true, y_pred, target_names=label_map)\n",
    "\n",
    "    print(f\"\\n--- Classification Report: {set_name} Set ---\\n\")\n",
    "    print(report)\n",
    "\n",
    "    # Save report as a text file\n",
    "    report_path = os.path.join(\n",
    "        output_dir, f\"classification_report_{set_name.lower()}.txt\"\n",
    "    )\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"Classification report saved at: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(generator, model, label_map, set_name, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluates model performance by generating a confusion matrix and classification report.\n",
    "    \"\"\"\n",
    "    y_true = generator.classes  # True labels\n",
    "    y_pred_probs = model.predict(generator)  # Model predictions (probabilities)\n",
    "    y_pred = (y_pred_probs[:, 1] > threshold).astype(\n",
    "        int\n",
    "    )  # Convert to binary class labels\n",
    "\n",
    "    print(f\"\\n#### {set_name} Set Evaluation ####\\n\")\n",
    "\n",
    "    # Generate and display confusion matrix\n",
    "    generate_confusion_matrix(y_true, y_pred, label_map, set_name)\n",
    "\n",
    "    # Generate and print classification report\n",
    "    generate_classification_report(y_true, y_pred, label_map, set_name)\n",
    "\n",
    "\n",
    "# Get Class Labels from Training Set\n",
    "label_map = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Evaluate the MobileNetV2 Model on Train and Test Sets\n",
    "evaluate_model(train_generator, mobilenet_model, label_map, \"Train\")\n",
    "evaluate_model(test_generator, mobilenet_model, label_map, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "\n",
    "- Train Set: The model exhibits moderate misclassification between healthy and infected leaves, with precision and recall around 52%. This suggests the model struggles to distinguish between the two classes in the training set.\n",
    "\n",
    "- Test Set: The model performs significantly better, achieving near-perfect classification (precision, recall, and F1-score of 1.00). This indicates the model generalizes well, despite inconsistencies in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_prediction_histogram(model, generator, set_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Generates and saves a histogram of predicted probabilities from MobileNetV2.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained MobileNetV2 model\n",
    "    - generator: Data generator (e.g., train, validation, test)\n",
    "    - set_name: Name of the dataset (\"Train\", \"Validation\", \"Test\")\n",
    "    \"\"\"\n",
    "    # Get true labels and predicted probabilities\n",
    "    y_true = generator.classes\n",
    "    y_pred_probs = model.predict(generator)  # Get softmax probabilities\n",
    "\n",
    "    # Extract probability scores for class 1 (positive class)\n",
    "    y_pred_class1_probs = y_pred_probs[:, 1]  # Assumes binary classification\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(y_pred_class1_probs, bins=20, kde=True, color=\"blue\", alpha=0.7)\n",
    "    plt.axvline(x=0.5, color=\"red\", linestyle=\"dashed\", label=\"Threshold = 0.5\")\n",
    "    plt.title(f\"Prediction Probability Histogram - {set_name} Set\")\n",
    "    plt.xlabel(\"Predicted Probability for Class 1 (Powdery Mildew)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save histogram\n",
    "    hist_path = f\"outputs/v3/histogram_{set_name.lower()}.png\"\n",
    "    plt.savefig(hist_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Histogram saved at: {hist_path}\")\n",
    "\n",
    "\n",
    "# Run histogram plot for test set\n",
    "plot_prediction_histogram(mobilenet_model, test_generator, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def plot_roc_curve(model, generator, set_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Generates and saves an ROC curve for MobileNetV2 predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained MobileNetV2 model\n",
    "    - generator: Data generator (e.g., train, validation, test)\n",
    "    - set_name: Name of the dataset (\"Train\", \"Validation\", \"Test\")\n",
    "    \"\"\"\n",
    "    # Get true labels and predicted probabilities\n",
    "    y_true = generator.classes\n",
    "    y_pred_probs = model.predict(generator)  # Get softmax probabilities\n",
    "\n",
    "    # Extract probability scores for class 1 (positive class)\n",
    "    y_pred_class1_probs = y_pred_probs[:, 1]  # Assumes binary classification\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_class1_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "    plt.plot(\n",
    "        [0, 1], [0, 1], color=\"gray\", linestyle=\"--\"\n",
    "    )  # Diagonal line (random guessing)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.title(f\"ROC Curve - {set_name} Set\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Save ROC curve\n",
    "    roc_path = f\"outputs/v3/roc_curve_{set_name.lower()}.png\"\n",
    "    plt.savefig(roc_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"ROC Curve saved at: {roc_path}\")\n",
    "\n",
    "\n",
    "# Run ROC curve plot for test set\n",
    "plot_roc_curve(mobilenet_model, test_generator, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Store evaluation results with the correct variable names\n",
    "evaluation_mobilenet = {\n",
    "    \"test_loss\": test_loss_mobilenet,\n",
    "    \"test_accuracy\": test_accuracy_mobilenet,\n",
    "}\n",
    "\n",
    "# Save evaluation results\n",
    "joblib.dump(value=evaluation_mobilenet, filename=\"outputs/v3/evaluation_mobilenet.pkl\")\n",
    "print(\"\\nMobileNetV2 model evaluation results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark: Overfitting Analysis (Base CNN)**\n",
    "\n",
    "The training and validation curves show consistent trends, indicating that the model generalizes well without significant overfitting.\n",
    "\n",
    "Key Observations:\n",
    "- Training vs. Validation Accuracy: Both curves closely follow each other, with final validation accuracy (0.9762) slightly higher than training accuracy (0.9500).\n",
    "- Training vs. Validation Loss: The loss values remain similar, suggesting that the model is not memorizing the training data but learning meaningful patterns.\n",
    "- No sharp divergence between training and validation metrics, reinforcing that overfitting is not a major concern.\n",
    "\n",
    "Conclusion: The base CNN demonstrates good generalization, making it a reliable baseline for further improvements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the CNN model using Keras Tuner to improve performance while preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,  \n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tuned_mobilenetv2(hp):\n",
    "    \"\"\"\n",
    "    Builds a MobileNetV2 model with tunable hyperparameters.\n",
    "    \"\"\"\n",
    "    # Load MobileNetV2 with pre-trained weights, excluding the top classification layer\n",
    "    base_model = MobileNetV2(\n",
    "        weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3)\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze layers\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(hp.Choice(\"dense_units\", [64, 128, 256]), activation=\"relu\"),\n",
    "            Dropout(hp.Choice(\"dropout\", [0.2, 0.3, 0.4])),\n",
    "            Dense(2, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Tune learning rate\n",
    "    learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.0005, 0.0001])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the tuner\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_tuned_mobilenetv2,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=7,  # Balanced between speed & tuning\n",
    "    directory=\"keras_tuner_results\",\n",
    "    project_name=\"mobilenetv2_tuning\",\n",
    ")\n",
    "\n",
    "# Load dataset from ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "dataset_path = \"inputs/mildew_dataset/cherry-leaves/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=os.path.join(dataset_path, \"train\"),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=os.path.join(dataset_path, \"validation\"),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    ")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "tuner.search(train_generator, epochs=7, validation_data=val_generator)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "Best hyperparameters:\n",
    "- Dense Units: {best_hps.get('dense_units')}\n",
    "- Dropout: {best_hps.get('dropout')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Train the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(train_generator, epochs=12, validation_data=val_generator)\n",
    "\n",
    "# Save the best model\n",
    "best_model.save(\"outputs/tuned_mobilenetv2.h5\")\n",
    "print(\"Best MobileNetV2 model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Search Space\n",
    "The hyperparameter values were selected based on a balance between model performance, generalization ability, and computational efficiency. The choices aim to enhance feature extraction while preventing overfitting and maintaining training stability.\n",
    "\n",
    "| **Hyperparameter**       | **Values Tested**       | **Rationale** |\n",
    "|-------------------------|------------------------|--------------|\n",
    "| **Number of Filters** (num_filters_1 to num_filters_4) | [32, 64, 128, 256] | Increasing filter sizes in deeper layers helps extract hierarchical features while balancing computational cost. |\n",
    "| **L2 Regularization** (l2_reg) | [0.0001, 0.001, 0.0005] | Helps prevent overfitting by applying weight penalties, ensuring smooth generalization. |\n",
    "| **Dropout Rate** (dropout_rate) | [0.2, 0.3] | Reduces overfitting by randomly deactivating neurons during training. Moderate dropout rates retain learning capacity while preventing memorization. |\n",
    "| **Learning Rate** (learning_rate) | [0.0001, 0.0003]| Chosen for stable convergence. Lower rates avoid overshooting minima, while slightly higher rates accelerate learning without destabilization. |\n",
    "\n",
    "The tuning process balances model complexity and generalization, ensuring optimal feature extraction without overfitting or excessive computational burden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Define the model function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input(shape=(128, 128, 3)),\n",
    "            # Moderate filter choices for efficiency\n",
    "            Conv2D(hp.Choice(\"conv1_filters\", [32, 64]), (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(hp.Choice(\"conv2_filters\", [64, 128]), (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            # Dense layer tuning with reasonable options\n",
    "            Dense(hp.Choice(\"dense_units\", [64, 128, 256]), activation=\"relu\"),\n",
    "            # Dropout tuning with moderate choices\n",
    "            Dropout(hp.Choice(\"dropout\", [0.2, 0.3, 0.4])),\n",
    "            Dense(2, activation=\"softmax\"),  # Using softmax for binary classification\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Learning rate tuning with reasonable range\n",
    "    learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.0005, 0.0001])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the tuner\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=7,  # Balanced between speed & finding a good model\n",
    "    directory=\"keras_tuner_results\",\n",
    "    project_name=\"mildew_detector_tuning_balanced\",\n",
    ")\n",
    "\n",
    "# Load dataset (Replace with actual data)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "# **Moderate epochs for better results without excessive training time**\n",
    "tuner.search(X_train, y_train, epochs=7, validation_data=(X_val, y_val))\n",
    "\n",
    "# Get the best hyperparameter combination\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "Best hyperparameters:\n",
    "- Conv1 Filters: {best_hps.get('conv1_filters')}\n",
    "- Conv2 Filters: {best_hps.get('conv2_filters')}\n",
    "- Dense Units: {best_hps.get('dense_units')}\n",
    "- Dropout: {best_hps.get('dropout')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Train the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(\n",
    "    X_train, y_train, epochs=12, validation_data=(X_val, y_val)\n",
    ")  # Train longer after tuning\n",
    "\n",
    "# Save the best model\n",
    "best_model.save(\"outputs/tuned_mildew_detector_balanced.h5\")\n",
    "print(\"Best model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Best Model & Store History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Best Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"outputs/v1/mildew_detector_cnn_tuned.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Tuned Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & Evaluate the Tuned Model\n",
    "best_model = tf.keras.models.load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
    "\n",
    "test_loss_tuned, test_accuracy_tuned = best_model.evaluate(test_set)\n",
    "\n",
    "print(\"\\n### Tuned Model Evaluation ###\")\n",
    "print(f\"Test Accuracy: {test_accuracy_tuned:.4f}\")\n",
    "print(f\"Test Loss: {test_loss_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Training History to DataFrame (Tuned CNN)\n",
    "import pandas as pd\n",
    "\n",
    "df_history_tuned_cnn = pd.DataFrame(history_tuned_cnn.history)\n",
    "\n",
    "# Save history for later use\n",
    "df_history_tuned_cnn.to_csv(\"outputs/v1/history_tuned_cnn.csv\", index=False)\n",
    "print(\"Tuned CNN training history saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning Curve (Loss & Accuracy) for Tuned CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot Loss Curve\n",
    "df_history_tuned_cnn[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy Curve\n",
    "df_history_tuned_cnn[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/model_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix & Classification Report for Tuned CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = \"outputs/v1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to Generate Confusion Matrix\n",
    "def generate_confusion_matrix(y_true, y_pred, label_map, set_name):\n",
    "    \"\"\"\n",
    "    Generates, displays, and saves a static confusion matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Actual class labels\n",
    "    - y_pred: Predicted class labels\n",
    "    - label_map: List of class names\n",
    "    - set_name: Dataset name (Train, Validation, Test)\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=label_map, columns=label_map)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5)\n",
    "    plt.title(f\"Confusion Matrix - {set_name} Set\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show confusion matrix\n",
    "    save_path = os.path.join(output_dir, f\"confusion_matrix_{set_name.lower()}.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.show()  # Display in the notebook\n",
    "    print(f\"Confusion Matrix saved at: {save_path}\")\n",
    "\n",
    "# Function to Generate Classification Report\n",
    "def generate_classification_report(y_true, y_pred, label_map, set_name):\n",
    "    \"\"\"\n",
    "    Generates, prints, and saves a classification report.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Actual class labels\n",
    "    - y_pred: Predicted class labels\n",
    "    - label_map: List of class names\n",
    "    - set_name: Dataset name (Train, Validation, Test)\n",
    "    \"\"\"\n",
    "    report = classification_report(y_true, y_pred, target_names=label_map)\n",
    "    \n",
    "    print(f\"\\n--- Classification Report: {set_name} Set ---\\n\")\n",
    "    print(report)\n",
    "\n",
    "    # Save report as a text file\n",
    "    report_path = os.path.join(output_dir, f\"classification_report_{set_name.lower()}.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"Classification report saved at: {report_path}\")\n",
    "\n",
    "# Function to Evaluate the Model\n",
    "def evaluate_model(generator, model, label_map, set_name, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluates model performance by generating a confusion matrix and classification report.\n",
    "    \n",
    "    Parameters:\n",
    "    - generator: Data generator (train, validation, or test)\n",
    "    - model: Trained model\n",
    "    - label_map: List of class names\n",
    "    - set_name: Dataset name (Train, Validation, Test)\n",
    "    - threshold: Probability threshold for classification (default: 0.5)\n",
    "    \"\"\"\n",
    "    y_true = generator.classes  # True labels\n",
    "    y_pred_probs = model.predict(generator)  # Model predictions (probabilities)\n",
    "    y_pred = (y_pred_probs > threshold).astype(int).flatten()  # Convert to class labels\n",
    "\n",
    "    print(f\"\\n#### {set_name} Set Evaluation ####\\n\")\n",
    "\n",
    "    # Generate and display confusion matrix\n",
    "    generate_confusion_matrix(y_true, y_pred, label_map, set_name)\n",
    "\n",
    "    # Generate and print classification report\n",
    "    generate_classification_report(y_true, y_pred, label_map, set_name)\n",
    "\n",
    "# Load the Tuned CNN Model\n",
    "tuned_model_path = \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
    "tuned_model = load_model(tuned_model_path)  \n",
    "\n",
    "# Get class labels from training set\n",
    "label_map = list(train_set.class_indices.keys())\n",
    "\n",
    "# Evaluate the Tuned Model on Train and Test Sets\n",
    "evaluate_model(train_set, tuned_model, label_map, \"Train\")\n",
    "evaluate_model(test_set, tuned_model, label_map, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Compute ROC Curve\n",
    "fpr_tuned, tpr_tuned, _ = roc_curve(\n",
    "    y_true_tuned, y_pred_tuned\n",
    ")  # True labels & predicted probabilities\n",
    "roc_auc_tuned = auc(fpr_tuned, tpr_tuned)  # Compute AUC Score\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(\n",
    "    fpr_tuned,\n",
    "    tpr_tuned,\n",
    "    color=\"blue\",\n",
    "    lw=2,\n",
    "    label=f\"Tuned CNN (AUC = {roc_auc_tuned:.2f})\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\", label=\"Random Classifier\")\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "plt.title(\"ROC Curve for Tuned CNN\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Save and Show Plot\n",
    "plt.savefig(\"outputs/v1/roccurve_tuned_cnn.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print AUC Score\n",
    "print(\"AUC Score (Tuned CNN):\", roc_auc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tuned CNN Model Evaluation Summary**\n",
    "\n",
    "#### **Training Set Performance**\n",
    "- **Accuracy:** 52%  \n",
    "- **Precision, Recall, F1-score:** 0.52 for both Healthy and Infected classes  \n",
    "- **Key Insight:** The training performance suggests that the model may not have fully learned class distinctions, as accuracy is close to random guessing.\n",
    "\n",
    "#### **Test Set Performance**\n",
    "- **Accuracy:** 100%  \n",
    "- **Precision, Recall, F1-score:** 1.00 for both Healthy and Infected classes  \n",
    "- **Key Insight:** The model perfectly classifies test samples, indicating **overfitting** on the training data.\n",
    "\n",
    "#### **Possible Concern**\n",
    "- The extreme difference in accuracy between training (52%) and test (100%) suggests **potential overfitting**, meaning the model might have memorized the test data rather than generalizing well.\n",
    "- Further analysis, such as **cross-validation or additional regularization**, may be necessary to ensure the model's robustness.\n",
    "\n",
    "**Conclusion:** While the Tuned CNN performs **perfectly on test data**, its poor training accuracy signals the need for further investigation to prevent overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison & Final Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Both Models and Training Histories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "# Load Base CNN Model\n",
    "base_cnn_model = load_model(\"outputs/v1/mildew_detector_base_cnn.keras\")\n",
    "\n",
    "# Load Tuned CNN Model\n",
    "tuned_cnn_model = load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
    "\n",
    "# Load Training Histories\n",
    "history_base = pd.read_csv(\"outputs/v1/history_base_cnn.csv\")\n",
    "history_tuned = pd.read_csv(\"outputs/v1/history_tuned_cnn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Accuracy & Loss Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure correct variable names are used\n",
    "models = [\"Base CNN\", \"Tuned CNN\"]\n",
    "accuracy_values = [test_accuracy_base_cnn, test_accuracy_tuned]\n",
    "loss_values = [test_loss_base_cnn, test_loss_tuned]\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "\n",
    "# Plot Accuracy Comparison\n",
    "ax[0].bar(models, accuracy_values, color=[\"blue\", \"green\"])\n",
    "ax[0].set_ylabel(\"Test Accuracy\")\n",
    "ax[0].set_title(\"Accuracy Comparison: Base CNN vs. Tuned CNN\")\n",
    "ax[0].set_ylim(0, 1)  # Ensure accuracy is within [0,1]\n",
    "ax[0].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Fix warning by setting ticks first\n",
    "ax[0].set_xticks(range(len(models)))\n",
    "ax[0].set_xticklabels([f\"{models[i]} ({accuracy_values[i]:.4f})\" for i in range(len(models))])\n",
    "\n",
    "# Plot Loss Comparison\n",
    "ax[1].bar(models, loss_values, color=[\"red\", \"purple\"])\n",
    "ax[1].set_ylabel(\"Test Loss\")\n",
    "ax[1].set_title(\"Loss Comparison: Base CNN vs. Tuned CNN\")\n",
    "ax[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Fix warning by setting ticks first\n",
    "ax[1].set_xticks(range(len(models)))\n",
    "ax[1].set_xticklabels([f\"{models[i]} ({loss_values[i]:.4f})\" for i in range(len(models))])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Metrics (Accuracy, Precision, Recall, F1-Score, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Get true labels from test set\n",
    "y_true = test_set.classes  # Works if using ImageDataGenerator\n",
    "\n",
    "# Get model predictions (convert probabilities to binary)\n",
    "y_pred_base = (base_cnn_model.predict(test_set) > 0.5).astype(\"int32\").flatten()\n",
    "y_pred_tuned = (tuned_cnn_model.predict(test_set) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Get probability predictions for AUC\n",
    "y_pred_base_prob = base_cnn_model.predict(test_set).flatten()\n",
    "y_pred_tuned_prob = tuned_cnn_model.predict(test_set).flatten()\n",
    "\n",
    "# Compute Accuracy, Precision, Recall, F1-score\n",
    "report_base = classification_report(y_true, y_pred_base, output_dict=True)\n",
    "report_tuned = classification_report(y_true, y_pred_tuned, output_dict=True)\n",
    "\n",
    "# Compute AUC Score\n",
    "auc_base = roc_auc_score(y_true, y_pred_base_prob)\n",
    "auc_tuned = roc_auc_score(y_true, y_pred_tuned_prob)\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n### Base CNN Evaluation ###\")\n",
    "print(f\"Test Accuracy: {report_base['accuracy']:.4f}\")\n",
    "print(f\"Precision: {report_base['1']['precision']:.4f}\")\n",
    "print(f\"Recall: {report_base['1']['recall']:.4f}\")\n",
    "print(f\"F1-score: {report_base['1']['f1-score']:.4f}\")\n",
    "print(f\"AUC Score: {auc_base:.4f}\")\n",
    "\n",
    "print(\"\\n### Tuned CNN Evaluation ###\")\n",
    "print(f\"Test Accuracy: {report_tuned['accuracy']:.4f}\")\n",
    "print(f\"Precision: {report_tuned['1']['precision']:.4f}\")\n",
    "print(f\"Recall: {report_tuned['1']['recall']:.4f}\")\n",
    "print(f\"F1-score: {report_tuned['1']['f1-score']:.4f}\")\n",
    "print(f\"AUC Score: {auc_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Best Model & Save It for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on AUC score\n",
    "best_model = tuned_cnn_model if auc_tuned > auc_base else base_cnn_model\n",
    "best_model_name = \"Tuned CNN\" if auc_tuned > auc_base else \"Base CNN\"\n",
    "\n",
    "# Save the best model for deployment\n",
    "best_model.save(\"outputs/v1/final_mildew_detector.keras\")\n",
    "\n",
    "print(\"\\n### Best Model Selected & Saved ###\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(\"Model saved as 'final_mildew_detector.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Tuned CNN model outperformed the Base CNN** in Recall and AUC score, making it the better model for detecting powdery mildew. While accuracy was similar, the Tuned CNN had higher sensitivity, ensuring that infected leaves were detected correctly.Thus, the **Tuned CNN is selected as the final model** for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Goal Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model achieved an accuracy of **99.2%**, surpassing the business requirement of **≥90%** accuracy.\n",
    "Additionally, the model’s **high recall (97%)** ensures fewer false negatives, making it reliable for early detection.\n",
    "This model is now **ready for deployment** in an automated detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency Maps for Tuned CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency maps help visualize which parts of an image were most influential in the model’s classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2  # OpenCV for better heatmap visualization\n",
    "\n",
    "# Load the Tuned CNN Model\n",
    "tuned_model_path = \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
    "tuned_model = tf.keras.models.load_model(tuned_model_path)\n",
    "\n",
    "# Define a Function to Compute and Enhance Saliency Maps\n",
    "def compute_saliency_map(model, image, class_index):\n",
    "    \"\"\"\n",
    "    Computes a Saliency Map to highlight important pixels influencing the model's decision.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained CNN model\n",
    "    - image: Input image (single sample)\n",
    "    - class_index: Target class index (0 for Healthy, 1 for Infected)\n",
    "\n",
    "    Returns:\n",
    "    - Enhanced saliency map as a NumPy array\n",
    "    \"\"\"\n",
    "    image = tf.convert_to_tensor(image[None], dtype=tf.float32)  # Add batch dimension\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        preds = model(image)\n",
    "        loss = preds[:, class_index]  # Focus on the target class\n",
    "\n",
    "    grads = tape.gradient(loss, image)[0]  # Compute gradients\n",
    "    saliency = np.max(np.abs(grads), axis=-1)  # Take max across color channels\n",
    "\n",
    "    # Normalize Saliency Map\n",
    "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-8)  # Normalize between 0-1\n",
    "\n",
    "    # Apply Exponential Scaling to Enhance Weak Signals\n",
    "    saliency = np.power(saliency, 3)  # Amplify small differences\n",
    "\n",
    "    # Convert to 8-bit (0-255) for Better Visualization\n",
    "    saliency = (saliency * 255).astype(np.uint8)\n",
    "\n",
    "    # Apply Histogram Equalization to Improve Contrast\n",
    "    saliency = cv2.equalizeHist(saliency)\n",
    "\n",
    "    # Apply a Stronger Colormap for More Visible Heatmap\n",
    "    saliency_colored = cv2.applyColorMap(saliency, cv2.COLORMAP_HOT)  # Use 'HOT' colormap for high contrast\n",
    "\n",
    "    return saliency_colored\n",
    "\n",
    "# Select a Test Image\n",
    "sample_index = 7  # Adjust if needed\n",
    "X_test_batch, y_test_batch = next(iter(test_set))  # Extract a batch\n",
    "sample_image = X_test_batch[sample_index]  # Select one test image\n",
    "sample_label = int(y_test_batch[sample_index])  # Convert label to integer\n",
    "\n",
    "# Compute Saliency Map\n",
    "saliency = compute_saliency_map(tuned_model, sample_image, class_index=sample_label)\n",
    "\n",
    "# Display the Original Image and Enhanced Saliency Map\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Show Original Image \n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.clip(sample_image * 255, 0, 255).astype(\"uint8\"))  \n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original Image (Enhanced Contrast)\")\n",
    "\n",
    "# Show Strongly Enhanced Saliency Map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(saliency, cv2.COLOR_BGR2RGB))  # Convert OpenCV BGR to RGB\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Strongly Enhanced Saliency Map\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "\n",
    "The Saliency Map highlights the most influential regions that guided the CNN’s classification decisions.\n",
    "\n",
    "- Bright yellow/orange areas indicate the regions the model prioritized for classification.\n",
    "- The model focuses on specific patterns and textures rather than random noise, confirming its ability to extract meaningful features.\n",
    "- Saliency regions vary across images, suggesting that the CNN adapts dynamically based on the input.\n",
    "\n",
    "This analysis reinforces the model’s interpretability, demonstrating that its predictions are based on relevant visual features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Predict on Sample Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the final trained model\n",
    "model = load_model(\"outputs/v1/final_mildew_detector.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Load a Random Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Define test image selection parameters\n",
    "pointer = 60  # Change this number to select a different image\n",
    "label = labels[1]  # Select \"Healthy\" (0) or \"Infected\" (1)\n",
    "\n",
    "# Load the image using PIL\n",
    "img_path = test_path + \"/\" + label + \"/\" + os.listdir(test_path + \"/\" + label)[pointer]\n",
    "pil_image = image.load_img(img_path, target_size=image_shape, color_mode=\"rgb\")\n",
    "\n",
    "# Display image details\n",
    "print(f\"Selected Image Path: {img_path}\")\n",
    "print(f\"Image shape: {pil_image.size}, Image mode: {pil_image.mode}\")\n",
    "\n",
    "# Show the image\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction & Display Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "pred_proba = model.predict(my_image)[0, 0]  # Extract single probability score\n",
    "\n",
    "# Map indices to class labels\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}  # Reverse mapping\n",
    "pred_class = target_map[int(pred_proba > 0.5)]  # Ensure correct label mapping\n",
    "\n",
    "# Adjust probability if necessary\n",
    "if pred_class == target_map[0]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "# Print prediction results\n",
    "print(f\"Predicted Class: {pred_class}\")\n",
    "print(f\"Prediction Probability: {pred_proba:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we successfully developed a deep learning model to detect Powdery Mildew on Cherry Leaves using a structured, beginner-friendly approach.\n",
    "\n",
    "## Key Achievements\n",
    "- Baseline CNN Implementation → Developed an initial CNN model to establish a performance benchmark.\n",
    "- Optimized Hyperparameter Tuning → Applied systematic tuning (adjusting filters, dropout, learning rate, and L2 regularization) to enhance model performance while balancing computational efficiency.\n",
    "- Model Evaluation & Comparison → Assessed the baseline and optimized CNN models based on accuracy, loss, and generalization ability.\n",
    "- Explainability with Saliency Maps → Visualized important regions influencing the model’s predictions, enhancing interpretability.\n",
    "- Final Model Selection → The Hyperparameter-Tuned CNN was chosen based on its superior accuracy and robustness for real-world deployment.\n",
    "\n",
    "## Next Steps: Model Deployment\n",
    "\n",
    "The next step is to integrate the optimized CNN model into a user-friendly application that allows real-time classification of leaf images.\n",
    "\n",
    "Deployment Plan\n",
    "- Develop an Interactive Web App → Implement a Streamlit-based interface where users can upload leaf images for classification.\n",
    "- Integrate the Tuned CNN Model → Load the trained model to process new images and predict mildew presence.\n",
    "- Deploy on a Cloud Platform → Host the web application using Streamlit and Heroku for accessibility.\n",
    "\n",
    "This deployment will enable real-time detection of powdery mildew, aiding efficient disease monitoring and automated plantation management.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
