{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Modeling and Evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer Business Requirement 2: Develop a Machine Learning model to classify cherry leaves as Healthy or Infected, enabling the prediction of powdery mildew presence.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Dataset\n",
    "- inputs/mildew_dataset/cherry-leaves/train\n",
    "- inputs/mildew_dataset/cherry-leaves/validation\n",
    "- inputs/mildew_dataset/cherry-leaves/test\n",
    "\n",
    "Precomputed Features (from Data Visualization Notebook)\n",
    "- Image Shape Standardization → 128x128x3 for consistency across models.\n",
    "- Class Distribution Analysis → Ensures balanced dataset splits.\n",
    "- Pixel Intensity Distribution → Confirms brightness variations relevant for classification.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "### Data Processing & Visualization\n",
    "- **Dataset Distribution Plot** → Confirms balanced data split across training, validation, and test sets.  \n",
    "- **Data Augmentation Visualization** → Showcases applied transformations (rotation, flipping, zooming).  \n",
    "\n",
    "### Model Training & Evaluation\n",
    "- **Baseline CNN Models (Sigmoid & Softmax)** → Initial experiments to establish a benchmark.  \n",
    "- **MobileNetV2 Fine-Tuning** → Explored optimized architectures with different hyperparameters.  \n",
    "- **Best Model Selection** → Chose the most balanced model based on test accuracy, generalization, and robustness.  \n",
    "- **Saved Trained Model** → Final MobileNetV2 model stored for deployment.  \n",
    "\n",
    "### Model Performance & Explainability\n",
    "- **Learning Curves** → Visualizes loss and accuracy trends over epochs.  \n",
    "- **Histograms** → Displays predicted probability distributions.  \n",
    "- **Overfitting & Generalization Check** → Assesses potential overfitting using accuracy and loss gaps.  \n",
    "- **Confusion Matrices** → Shows classification performance for train, validation, and test sets.  \n",
    "- **Classification Reports** → Provides precision, recall, and F1-score analysis.  \n",
    "- **ROC Curves** → Evaluates model performance using Receiver Operating Characteristic analysis.  \n",
    "- **Business Goal Validation** → Confirms if the model meets the required accuracy threshold.  \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "- **Business Impact:** Enables early detection of powdery mildew, reducing manual inspection and improving monitoring.  \n",
    "- **Data-Driven Improvements:** Model refinements were based on data insights, ensuring balanced class distribution.  \n",
    "- **Deployment:** The optimized model is ready for Streamlit integration for real-world use.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/workspaces/mildew-detector\")\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "#### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "## Set Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directories\n",
    "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
    "train_path = os.path.join(my_data_dir, 'train')\n",
    "val_path = os.path.join(my_data_dir, 'validation')\n",
    "test_path = os.path.join(my_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels for the images\n",
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images in Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dictionary\n",
    "data = {\n",
    "    'Set': [],\n",
    "    'Label': [],\n",
    "    'Frequency': []\n",
    "}\n",
    "\n",
    "# Define dataset folders\n",
    "folders = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each dataset split and count images\n",
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        path = os.path.join(my_data_dir, folder, label)\n",
    "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  \n",
    "        data['Set'].append(folder)\n",
    "        data['Label'].append(label)\n",
    "        data['Frequency'].append(num_images)\n",
    "        print(f\" {folder}/{label}: {num_images} images\")\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_freq = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart - Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.title(\"Image Distribution in Dataset\")\n",
    "plt.xlabel(\"Dataset Split\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow/Keras ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize ImageDataGenerator for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation for Training Set\n",
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Training Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Validation Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augment Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Augmented Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Augmented Images in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augmented_images_grid(data_generator, num_images=10):\n",
    "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
    "    img_batch, label_batch = next(data_generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
    "        ax.imshow(img_batch[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image grid\n",
    "plot_augmented_images_grid(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2 was chosen for its efficiency, speed, and strong feature extraction while maintaining high accuracy with fewer parameters. Its lightweight architecture makes it ideal for deployment in resource-constrained environments. Details are provided in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter\n",
    "learning_rate = 0.00005\n",
    "l2_lambda = 0.004\n",
    "dropout_rate = 0.65\n",
    "activation_function = \"tanh\"\n",
    "patience_value = 4\n",
    "\n",
    "# Create MobileNetV2 Model\n",
    "model_mobilenet = Sequential(\n",
    "    [\n",
    "        MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3)),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation=activation_function, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile Model\n",
    "model_mobilenet.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Summary\n",
    "model_mobilenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Start time tracking\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Set EarlyStopping & Learning Rate Scheduler\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", patience=patience_value, restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")\n",
    "\n",
    "m_checkpoint = ModelCheckpoint(\n",
    "    filepath=\"outputs/mobilenet.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "history_mobilenet = model_mobilenet.fit(\n",
    "    train_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stop, lr_scheduler, m_checkpoint],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobilenet.save(\"outputs/v1/mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Extract history from the training process\n",
    "history_dict = history_mobilenet.history\n",
    "\n",
    "# Convert history dictionary to a long format for Plotly\n",
    "df_long = pd.DataFrame({\n",
    "    'Epoch': range(1, len(history_dict['loss']) + 1),\n",
    "    'loss': history_dict['loss'],\n",
    "    'val_loss': history_dict['val_loss'],\n",
    "    'accuracy': history_dict['accuracy'],\n",
    "    'val_accuracy': history_dict['val_accuracy']\n",
    "})\n",
    "\n",
    "# Convert to long format\n",
    "df_long = df_long.melt(id_vars=[\"Epoch\"], value_vars=[\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"],\n",
    "                       var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "# Split into two DataFrames: one for loss, one for accuracy\n",
    "df_loss = df_long[df_long[\"Metric\"].isin([\"loss\", \"val_loss\"])]\n",
    "df_acc = df_long[df_long[\"Metric\"].isin([\"accuracy\", \"val_accuracy\"])]\n",
    "\n",
    "# Interactive Loss Curve\n",
    "fig_loss = px.line(\n",
    "    df_loss,\n",
    "    x=\"Epoch\",\n",
    "    y=\"Value\",\n",
    "    color=\"Metric\",\n",
    "    markers=True,\n",
    "    title=\"Loss - MobileNetV2\",\n",
    "    labels={\"Value\": \"Loss\", \"Epoch\": \"Epoch\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Interactive Accuracy Curve\n",
    "fig_acc = px.line(\n",
    "    df_acc,\n",
    "    x=\"Epoch\",\n",
    "    y=\"Value\",\n",
    "    color=\"Metric\",\n",
    "    markers=True,\n",
    "    title=\"Accuracy - MobileNetV2\",\n",
    "    labels={\"Value\": \"Accuracy\", \"Epoch\": \"Epoch\"},\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Save the figures as static PNGs\n",
    "fig_loss.write_image(f\"{output_dir}/model_training_losses.png\", scale=2)\n",
    "fig_acc.write_image(f\"{output_dir}/model_training_acc.png\", scale=2)\n",
    "\n",
    "# Show interactive plots\n",
    "fig_loss.show()\n",
    "fig_acc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy:** Training accuracy quickly reaches **~1.0**, while validation accuracy steadily improves with a small gap (~1%).  \n",
    "- **Loss:** Both training and validation loss decrease consistently, showing stable learning with **no major overfitting**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model_mobilenet = load_model(\"outputs/v1/mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model_mobilenet.evaluate(test_set, batch_size=batch_size)\n",
    "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
    "print(\"Model Loss: \", evaluation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Accuracy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly obtain true labels\n",
    "y_true = test_set.labels\n",
    "\n",
    "# Obtain model predictions\n",
    "preds = model_mobilenet.predict(test_set)\n",
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram below shows the overall distribution of model confidence scores for predictions on the test set. To explore individual image confidence levels and analyze misclassifications, please refer to the interactive version in the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import psutil\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_probs = model_mobilenet.predict(validation_set)\n",
    "\n",
    "# Create DataFrame for Plotly\n",
    "df_probs = pd.DataFrame({\"Healthy\": y_pred_probs[:, 0], \"Infected\": y_pred_probs[:, 1]})\n",
    "\n",
    "# Create histogram traces for both classes\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_probs[\"Healthy\"],\n",
    "        nbinsx=20,\n",
    "        opacity=0.6,\n",
    "        name=\"Healthy\",\n",
    "        marker_color=\"green\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_probs[\"Infected\"],\n",
    "        nbinsx=20,\n",
    "        opacity=0.6,\n",
    "        name=\"Infected\",\n",
    "        marker_color=\"blue\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add threshold line at 0.5\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5, 0.5],\n",
    "        y=[\n",
    "            0,\n",
    "            max(np.histogram(y_pred_probs[:, 1], bins=20)[0]),\n",
    "        ],  # Adjust y-axis dynamically\n",
    "        mode=\"lines\",\n",
    "        name=\"Threshold = 0.5\",\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Prediction Probability Histogram\",\n",
    "    xaxis_title=\"Prediction Probability\",\n",
    "    yaxis_title=\"Count\",\n",
    "    barmode=\"overlay\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "fig.write_image(f\"{output_dir}/histogram_test.png\", scale=2)\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Cleanup Kaleido processes after saving the image\n",
    "def cleanup_kaleido():\n",
    "    for proc in psutil.process_iter([\"pid\", \"name\"]):\n",
    "        if \"kaleido\" in proc.info[\"name\"].lower():\n",
    "            os.kill(proc.info[\"pid\"], 9)  # Force kill\n",
    "\n",
    "\n",
    "cleanup_kaleido()  # Run cleanup to prevent zombie processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows a clear separation between **healthy** and **infected** predictions, with most probabilities concentrated near 0 and 1. The decision threshold at **0.5** is well-placed, ensuring confident classifications. Minimal overlap suggests strong model confidence in distinguishing between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import psutil\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Get Class Labels\n",
    "label_map = list(test_set.class_indices.keys())\n",
    "\n",
    "# Evaluate Model on Train and Test Sets\n",
    "y_true_train = train_set.classes\n",
    "y_pred_train = np.argmax(model_mobilenet.predict(train_set), axis=1)\n",
    "\n",
    "y_true_test = test_set.classes\n",
    "y_pred_test = np.argmax(model_mobilenet.predict(test_set), axis=1)\n",
    "\n",
    "# Generate Confusion Matrices for Train and Test Sets\n",
    "cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "\n",
    "# Convert confusion matrices to DataFrames\n",
    "df_cm_train = pd.DataFrame(cm_train, index=label_map, columns=label_map)\n",
    "df_cm_test = pd.DataFrame(cm_test, index=label_map, columns=label_map)\n",
    "\n",
    "# Function to create interactive Confusion Matrix\n",
    "def create_confusion_matrix_figure(conf_matrix, title):\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=conf_matrix.values,\n",
    "        x=conf_matrix.columns.tolist(),\n",
    "        y=conf_matrix.index.tolist(),\n",
    "        colorscale=\"Blues\",\n",
    "        showscale=True,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Predicted Label\",\n",
    "        yaxis_title=\"True Label\",\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# Create interactive plots for both train and test sets\n",
    "fig_train = create_confusion_matrix_figure(df_cm_train, \"Confusion Matrix - Train Set\")\n",
    "fig_test = create_confusion_matrix_figure(df_cm_test, \"Confusion Matrix - Test Set\")\n",
    "\n",
    "# Save Figures as Static PNGs\n",
    "fig_train.write_image(os.path.join(output_dir, \"confusion_matrix_train.png\"), scale=2)\n",
    "fig_test.write_image(os.path.join(output_dir, \"confusion_matrix_test.png\"), scale=2)\n",
    "\n",
    "# Show interactive plots one after another\n",
    "fig_train.show()\n",
    "fig_test.show()\n",
    "\n",
    "print(f\"Confusion Matrices saved at: {output_dir}/confusion_matrix_train.png & {output_dir}/confusion_matrix_test.png\")\n",
    "\n",
    "\n",
    "# Cleanup Kaleido processes after saving the image\n",
    "def cleanup_kaleido():\n",
    "    for proc in psutil.process_iter([\"pid\", \"name\"]):\n",
    "        if \"kaleido\" in proc.info[\"name\"].lower():\n",
    "            os.kill(proc.info[\"pid\"], 9)  # Force kill\n",
    "\n",
    "\n",
    "cleanup_kaleido()  # Run cleanup to prevent zombie processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well on both the training and test sets, with a high number of correct classifications. The test set shows **zero false positives**, meaning no healthy samples were misclassified as infected. A small number of false negatives (7 cases) suggest slight room for improvement in detecting infections, but overall accuracy remains strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Generate classification reports as text\n",
    "report_train = classification_report(\n",
    "    y_true_train, y_pred_train, target_names=label_map, digits=3\n",
    ")\n",
    "report_test = classification_report(\n",
    "    y_true_test, y_pred_test, target_names=label_map, digits=3\n",
    ")\n",
    "\n",
    "# Print Train Report\n",
    "print(\"\\n### Classification Report - Train Set ###\\n\")\n",
    "print(report_train)\n",
    "\n",
    "# Print Test Report\n",
    "print(\"\\n### Classification Report - Test Set ###\\n\")\n",
    "print(report_test)\n",
    "\n",
    "# Save reports as text files\n",
    "with open(f\"{output_dir}/classification_report_train.txt\", \"w\") as f:\n",
    "    f.write(report_train)\n",
    "\n",
    "with open(f\"{output_dir}/classification_report_test.txt\", \"w\") as f:\n",
    "    f.write(report_test)\n",
    "\n",
    "print(\"\\nReports saved to outputs/v1/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report indicates that the model performs well on the test set, with perfect precision, recall, and F1-scores (1.000) for both classes. However, the train set results are significantly lower, showing a possible issue with overfitting or insufficient training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "output_dir = \"outputs/v1\"\n",
    "\n",
    "# Generate predictions (probabilities) for both train and test sets\n",
    "y_probs_train = model_mobilenet.predict(train_set)\n",
    "y_probs_test = model_mobilenet.predict(test_set)\n",
    "\n",
    "# Compute ROC curve for train and test sets\n",
    "fpr_train, tpr_train, _ = roc_curve(y_true_train, y_probs_train[:, 1])\n",
    "fpr_test, tpr_test, _ = roc_curve(y_true_test, y_probs_test[:, 1])\n",
    "\n",
    "# Compute AUC for train and test sets\n",
    "auc_train = auc(fpr_train, tpr_train)\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Create an interactive Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Train ROC Curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr_train,\n",
    "        y=tpr_train,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Train AUC = {auc_train:.2f}\",\n",
    "        line=dict(color=\"blue\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add Test ROC Curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr_test,\n",
    "        y=tpr_test,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Test AUC = {auc_test:.2f}\",\n",
    "        line=dict(color=\"green\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add Random Guess Line (Baseline)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Random (AUC = 0.50)\",\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"ROC Curve - Train vs Test\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.7, y=0.2),\n",
    ")\n",
    "\n",
    "# Save the figure as a static PNG\n",
    "roc_curve_path = os.path.join(output_dir, \"roc_curve.png\")\n",
    "fig.write_image(roc_curve_path, scale=2)\n",
    "\n",
    "# Show interactive plot\n",
    "fig.show()\n",
    "\n",
    "print(f\"ROC Curve saved at: {roc_curve_path}\")\n",
    "\n",
    "\n",
    "# Cleanup Kaleido processes after saving the image\n",
    "def cleanup_kaleido():\n",
    "    for proc in psutil.process_iter([\"pid\", \"name\"]):\n",
    "        if \"kaleido\" in proc.info[\"name\"].lower():\n",
    "            os.kill(proc.info[\"pid\"], 9)  # Force kill\n",
    "\n",
    "\n",
    "cleanup_kaleido()  # Run cleanup to prevent zombie processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test ROC curve shows **perfect AUC (1.00)**, indicating strong model performance with **no false positives**. However, the train AUC is low (**0.49**), suggesting a potential issue in training evaluation. Further investigation may be needed to confirm the validity of the training metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Goal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results\n",
    "evaluation_results = joblib.load(\"outputs/v1/evaluation.pkl\")\n",
    "\n",
    "# Extract final test accuracy\n",
    "test_accuracy = evaluation_results[1]  # Since the second item is likely the accuracy\n",
    "\n",
    "# Check requirement\n",
    "accuracy_threshold = 0.90\n",
    "if test_accuracy >= accuracy_threshold:\n",
    "    print(f\"Model meets the business requirement! (Accuracy: {test_accuracy:.2%})\")\n",
    "else:\n",
    "    print(f\"Model does NOT meet the requirement. (Accuracy: {test_accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load random image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 66\n",
    "label = labels[0] \n",
    "pil_image = image.load_img(test_path + '/'+ label + '/'+ os.listdir(test_path+'/' + label)[pointer],\n",
    "                            target_size= image_shape, color_mode='rgb')\n",
    "\n",
    "print(f\" Image shape: {pil_image.size}, Image mode: {pil_image.mode}\")\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Image to Array and Prepare for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0) / 255.0  \n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model_mobilenet.predict(my_image)[0, 0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class = target_map[pred_proba < 0.5]\n",
    "\n",
    "if pred_class == target_map[1]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Record training duration\n",
    "end_time = time.time()\n",
    "training_time = round(end_time - start_time, 2)\n",
    "\n",
    "# Extract accuracy metrics from training history\n",
    "train_accuracy = round(history_mobilenet.history[\"accuracy\"][-1], 4)\n",
    "val_accuracy = round(history_mobilenet.history[\"val_accuracy\"][-1], 4)\n",
    "\n",
    "# Directly get test accuracy\n",
    "test_accuracy = (\n",
    "    round(test_accuracy, 4) if isinstance(test_accuracy, (int, float)) else None\n",
    ")\n",
    "\n",
    "# Measure inference time\n",
    "start_inf_time = time.time()\n",
    "model.predict(my_image)  # Run prediction on a sample image\n",
    "end_inf_time = time.time()\n",
    "\n",
    "# Calculate inference time per image\n",
    "inference_time = round((end_inf_time - start_inf_time), 4)\n",
    "\n",
    "# Determine overfitting risk\n",
    "overfitting_risk = \"Yes\" if train_accuracy - val_accuracy > 0.05 else \"No\"\n",
    "\n",
    "# Store results in a structured format\n",
    "results = {\n",
    "    \"Model\": \"MobileNetV2\",\n",
    "    \"Training Accuracy\": train_accuracy,\n",
    "    \"Validation Accuracy\": val_accuracy,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Training Time (sec)\": training_time,\n",
    "    \"Inference Time (sec/sample)\": inference_time,\n",
    "    \"Batch Size\": 16,\n",
    "    \"Overfitting Risk\": overfitting_risk,\n",
    "}\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "df_results = pd.DataFrame([results])\n",
    "\n",
    "# Save results to CSV (append mode)\n",
    "csv_file = \"training_results.csv\"\n",
    "df_results.to_csv(\n",
    "    csv_file, mode=\"a\", index=False, header=not pd.io.common.file_exists(csv_file)\n",
    ")\n",
    "\n",
    "# Display results as a table\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We successfully developed a deep learning model for image classification using a structured, beginner-friendly approach.  \n",
    "\n",
    "### **Key Achievements**\n",
    "- **Explored Multiple Architectures** → Compared Sigmoid, Softmax, and MobileNetV2 across different trials.  \n",
    "- **Comprehensive Evaluation** → Assessed models using accuracy, loss, confusion matrices, and ROC curves.  \n",
    "- **Optimized for Generalization** → Selected the best-performing model with minimal overfitting.  \n",
    "- **Deployment-Ready Model** → Finalized MobileNetV2 for real-world application.  \n",
    "\n",
    "### **Next Steps: Model Deployment**\n",
    "- **Web App Integration** → Implement a user-friendly Streamlit interface for real-time image classification.  \n",
    "- **Model Deployment** → Load the trained model and deploy it on a cloud platform for accessibility.  \n",
    "\n",
    "This deployment will enable efficient real-world usage, making automated classification accessible to users.  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
